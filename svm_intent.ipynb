{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNB+zOD8qGOVVw492/WUYkr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/44244432664/AIproj/blob/main/svm_intent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea\n",
        "!pip install underthesea[deep]\n",
        "!pip install textattack"
      ],
      "metadata": {
        "id": "59LQsSxlCz0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc708abe-6d5e-40b7-d351-e7b1f0d53aa1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-6.3.0-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.3)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.27.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2022.10.31)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.1.0)\n",
            "Installing collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.9 underthesea-6.3.0 underthesea-core-1.0.4\n",
            "Requirement already satisfied: underthesea[deep] in /usr/local/lib/python3.10/dist-packages (6.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (8.1.3)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (0.9.9)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (2.27.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (6.0)\n",
            "Requirement already satisfied: underthesea-core==1.0.4 in /usr/local/lib/python3.10/dist-packages (from underthesea[deep]) (1.0.4)\n",
            "Collecting torch<1.13,>=1.1.0 (from underthesea[deep])\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=3.5.0 (from underthesea[deep])\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<1.13,>=1.1.0->underthesea[deep]) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->underthesea[deep]) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=3.5.0->underthesea[deep])\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->underthesea[deep]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->underthesea[deep]) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->underthesea[deep]) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=3.5.0->underthesea[deep])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=3.5.0->underthesea[deep])\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea[deep]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea[deep]) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea[deep]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea[deep]) (3.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea[deep]) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea[deep]) (3.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.5.0->underthesea[deep]) (2023.6.0)\n",
            "Installing collected packages: tokenizers, safetensors, torch, huggingface-hub, transformers\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 torch-1.12.1 transformers-4.30.2\n",
            "Collecting textattack\n",
            "  Downloading textattack-0.3.8-py3-none-any.whl (418 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.7/418.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bert-score>=0.3.5 (from textattack)\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from textattack) (0.6.2)\n",
            "Collecting flair (from textattack)\n",
            "  Downloading flair-0.12.2-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from textattack) (3.12.2)\n",
            "Collecting language-tool-python (from textattack)\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Collecting lemminflect (from textattack)\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lru-dict (from textattack)\n",
            "  Downloading lru_dict-1.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Collecting datasets==2.4.0 (from textattack)\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textattack) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.10.1)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.12.1)\n",
            "Requirement already satisfied: transformers>=4.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (4.30.2)\n",
            "Collecting terminaltables (from textattack)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from textattack) (4.65.0)\n",
            "Collecting word2number (from textattack)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words (from textattack)\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from textattack) (9.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.7.1)\n",
            "Collecting pinyin==0.4.0 (from textattack)\n",
            "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from textattack) (0.42.1)\n",
            "Collecting OpenHowNet (from textattack)\n",
            "  Downloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
            "Collecting pycld2 (from textattack)\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click<8.1.0 (from textattack)\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (9.0.0)\n",
            "Collecting dill<0.3.6 (from datasets==2.4.0->textattack)\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (2.27.1)\n",
            "Collecting xxhash (from datasets==2.4.0->textattack)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.4.0->textattack)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (23.1)\n",
            "Collecting responses<0.19 (from datasets==2.4.0->textattack)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2022.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.6.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (0.3.1)\n",
            "Requirement already satisfied: gensim>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.3.1)\n",
            "Collecting segtok>=1.5.7 (from flair->textattack)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting mpld3==0.3 (from flair->textattack)\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.2)\n",
            "Collecting sqlitedict>=1.6.0 (from flair->textattack)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated>=1.2.4 (from flair->textattack)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.2.7)\n",
            "Collecting boto3 (from flair->textattack)\n",
            "  Downloading boto3-1.27.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.2 (from flair->textattack)\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.8.10)\n",
            "Collecting langdetect (from flair->textattack)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.9.2)\n",
            "Collecting ftfy (from flair->textattack)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting janome (from flair->textattack)\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gdown==4.4.0 (from flair->textattack)\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting conllu>=4.0 (from flair->textattack)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting wikipedia-api (from flair->textattack)\n",
            "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
            "Collecting pptree (from flair->textattack)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad (from flair->textattack)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.1 (from flair->textattack)\n",
            "  Downloading transformer_smaller_training_vocab-0.2.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair->textattack) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair->textattack) (4.11.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (1.2.0)\n",
            "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anytree (from OpenHowNet->textattack)\n",
            "  Downloading anytree-2.9.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (67.7.2)\n",
            "Collecting sentencepiece (from bpemb>=0.3.2->flair->textattack)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.4->flair->textattack) (1.14.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (1.3.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair->textattack) (6.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair->textattack) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair->textattack) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair->textattack) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair->textattack) (0.10.9.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair->textattack) (3.1.0)\n",
            "Requirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (3.20.3)\n",
            "Collecting botocore<1.31.0,>=1.30.0 (from boto3->flair->textattack)\n",
            "  Downloading botocore-1.30.0-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->flair->textattack)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->flair->textattack)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->flair->textattack) (0.2.6)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.4.0->textattack)\n",
            "  Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.20.2 (from transformers>=4.21.0->textattack)\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.4.0->flair->textattack) (2.4.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers>=4.21.0->textattack) (5.9.5)\n",
            "Building wheels for collected packages: pinyin, gdown, mpld3, pycld2, word2number, docopt, sqlitedict, langdetect, pptree\n",
            "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630476 sha256=e7b832e447e29627440e5b3c5fad113febe1cc00ef948d7d3acc1ff9b3ad59d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/38/af/616fc6f154aa5bae65a1da12b22d79943434269f0468ff9b3f\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=154bce3a5085b89d242d42be398e29f9e33adc315726eeef27b161122966f699\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/0b/3f/6ddf67a417a5b400b213b0bb772a50276c199a386b12c06bfc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116685 sha256=6f8ccee0efca854266ecfa5a7d042fda84726406852cb878a32645360faaf922\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/92/f7/45d9aac5dcfb1c2a1761a272365599cc7ba1050ce211a3fd9a\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=9915782 sha256=3cf34dd52a1497ae7b078ab15957ce25826bd98b86b426527f518aee7f7432b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5569 sha256=1ecfd8c2e5a1ea06fb40c48e42961de913551dfa5b9fbbfe69aec3ffa8465f15\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=62f040ee4e726ca1b4b852dbbb41ae3b1b488598686fa8c114d955491dc099d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=f54eed9f1d6b2bc33b005f1655747740981177527d6977acdb8250b74cd94638\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=d636bae6fed1559656277060d00dd466b076304e143d86686c5fb132b9aac440\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4609 sha256=e1a37730f06c00b73fa59d351afb44d1f9944627ffdbe5196c439293534abe0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "Successfully built pinyin gdown mpld3 pycld2 word2number docopt sqlitedict langdetect pptree\n",
            "Installing collected packages: word2number, sqlitedict, sentencepiece, pycld2, pptree, pinyin, mpld3, lru-dict, janome, docopt, xxhash, terminaltables, segtok, num2words, lemminflect, langdetect, jmespath, ftfy, dill, deprecated, conllu, click, anytree, wikipedia-api, responses, pytorch-revgrad, OpenHowNet, multiprocess, language-tool-python, botocore, accelerate, s3transfer, gdown, bpemb, datasets, boto3, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.3\n",
            "    Uninstalling click-8.1.3:\n",
            "      Successfully uninstalled click-8.1.3\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed OpenHowNet-2.0 accelerate-0.20.3 anytree-2.9.0 bert-score-0.3.13 boto3-1.27.0 botocore-1.30.0 bpemb-0.3.4 click-8.0.4 conllu-4.5.3 datasets-2.4.0 deprecated-1.2.14 dill-0.3.5.1 docopt-0.6.2 flair-0.12.2 ftfy-6.1.1 gdown-4.4.0 janome-0.5.0 jmespath-1.0.1 langdetect-1.0.9 language-tool-python-2.7.1 lemminflect-0.2.3 lru-dict-1.2.0 mpld3-0.3 multiprocess-0.70.13 num2words-0.5.12 pinyin-0.4.0 pptree-3.1 pycld2-0.41 pytorch-revgrad-0.2.0 responses-0.18.0 s3transfer-0.6.1 segtok-1.5.11 sentencepiece-0.1.99 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.8 transformer-smaller-training-vocab-0.2.4 wikipedia-api-0.6.0 word2number-1.1 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "61LEODRSQCe1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from underthesea import word_tokenize\n",
        "from underthesea import text_normalize\n",
        "from underthesea import dependency_parse\n",
        "import csv\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from textattack.augmentation import EasyDataAugmenter\n",
        "\n",
        "import random\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# from nltk.stem import PorterStemmer\n",
        "# ps = PorterStemmer()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('QAI.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2849
        },
        "id": "ysatmh9rtFxm",
        "outputId": "889da648-0a52-4e9a-f370-7496c78dec72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    Q  \\\n",
              "0   Các Trường đại học khác có ngành Công nghệ thô...   \n",
              "1                  Khác nhau giữa ngành KHMT và KTMT?   \n",
              "2   Nếu ban đầu em học ngành KHMT, sau đó, em thấy...   \n",
              "3   Em muốn học làm robot, điều khiển từ xa các th...   \n",
              "4                       Học phí của ngành KHMT, KTMT?   \n",
              "..                                                ...   \n",
              "57  Cho em hỏi phương thức kết hợp khi nào mới có ...   \n",
              "58  Dạ em là thí sinh chuẩn bị thi đại học năm nay...   \n",
              "59  Dạ cho em hỏi trọng số các tiêu chí điểm trong...   \n",
              "60                                                NaN   \n",
              "61  Khoa KH & KT Máy tính có chương trình dành cho...   \n",
              "\n",
              "                                                    A   I  \n",
              "0   \\nTại ĐH Bách Khoa, Khoa KH & KT Máy tính, đào...   4  \n",
              "1   \\nKHMT:\\nNgành Khoa học Máy tính thuộc nhóm ng...   4  \n",
              "2   \\nSV được phép chuyển ngành nếu thỏa các điều ...   5  \n",
              "3        \\nKỹ thuật máy tính là 1 lựa chọn phù hợp.\\n   6  \n",
              "4   \\nTham khảo quy định về mức thu học phí năm họ...   7  \n",
              "..                                                ...  ..  \n",
              "57  \\nChào bạn, hiện tại vẫn chưa có thông tin về ...  19  \n",
              "58  \\nChào bạn, về vấn đề mật khẩu của tài khoản m...  21  \n",
              "59  \\nNăm 2023 hiện đang để trọng số của các cột đ...   1  \n",
              "60  \\nBộ hồ sơ Ưu tiên xét tuyển theo quy định của...   3  \n",
              "61  \\n- Khoa KH & KT Máy tính hiện có 2 chương trì...   1  \n",
              "\n",
              "[62 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a51007c3-4a10-4478-af50-1e729a22852f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>I</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Các Trường đại học khác có ngành Công nghệ thô...</td>\n",
              "      <td>\\nTại ĐH Bách Khoa, Khoa KH &amp; KT Máy tính, đào...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Khác nhau giữa ngành KHMT và KTMT?</td>\n",
              "      <td>\\nKHMT:\\nNgành Khoa học Máy tính thuộc nhóm ng...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nếu ban đầu em học ngành KHMT, sau đó, em thấy...</td>\n",
              "      <td>\\nSV được phép chuyển ngành nếu thỏa các điều ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Em muốn học làm robot, điều khiển từ xa các th...</td>\n",
              "      <td>\\nKỹ thuật máy tính là 1 lựa chọn phù hợp.\\n</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Học phí của ngành KHMT, KTMT?</td>\n",
              "      <td>\\nTham khảo quy định về mức thu học phí năm họ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Cho em hỏi phương thức kết hợp khi nào mới có ...</td>\n",
              "      <td>\\nChào bạn, hiện tại vẫn chưa có thông tin về ...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Dạ em là thí sinh chuẩn bị thi đại học năm nay...</td>\n",
              "      <td>\\nChào bạn, về vấn đề mật khẩu của tài khoản m...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Dạ cho em hỏi trọng số các tiêu chí điểm trong...</td>\n",
              "      <td>\\nNăm 2023 hiện đang để trọng số của các cột đ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nBộ hồ sơ Ưu tiên xét tuyển theo quy định của...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Khoa KH &amp; KT Máy tính có chương trình dành cho...</td>\n",
              "      <td>\\n- Khoa KH &amp; KT Máy tính hiện có 2 chương trì...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a51007c3-4a10-4478-af50-1e729a22852f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a51007c3-4a10-4478-af50-1e729a22852f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a51007c3-4a10-4478-af50-1e729a22852f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def read_csv(filename):\n",
        "#     q = []\n",
        "#     a = []\n",
        "#     i = []\n",
        "\n",
        "#     with open (filename) as csvDataFile:\n",
        "#         csvReader = csv.reader(csvDataFile)\n",
        "\n",
        "#         for row in csvReader:\n",
        "#             q.append(row[0])\n",
        "#             a.append(row[1])\n",
        "#             i.append(row[2])\n",
        "\n",
        "#     Q = np.asarray(q)\n",
        "#     A = np.asarray(a)\n",
        "#     # X = phrase\n",
        "#     I = np.asarray(i,)\n",
        "\n",
        "#     print(f'Q: {type(Q)}')\n",
        "#     print(f'A: {type(A)}')\n",
        "#     print(f'I: {type(I)}')\n",
        "\n",
        "#     return Q, A, I\n",
        "\n",
        "stop = pd.read_csv('stopwords.csv')\n",
        "stop_words = list(stop['stopwords'])\n",
        "print(stop_words)\n",
        "# print(Y)\n",
        "\n",
        "# def stat(Y):\n",
        "#   a=0\n",
        "#   b=0\n",
        "#   c=0\n",
        "#   for e in Y:\n",
        "#     if e==0:\n",
        "#       a+=1\n",
        "#     if e==1:\n",
        "#       b+=1\n",
        "#     if e==2:\n",
        "#       c+=1\n",
        "#   return a, b, c\n",
        "\n",
        "# a, b, c = stat(Y)\n",
        "# print(a, b, c)\n",
        "\n",
        "qai = pd.read_csv('QAI.csv')\n",
        "print(type(qai))\n",
        "print(type(qai['Q']))\n",
        "# print(type(qai.frame))\n",
        "Q = np.asarray(qai['Q'])\n",
        "A = np.asarray(qai['A'])\n",
        "I = np.asarray(qai['I'])\n",
        "Q_I = np.zeros(len(I))\n",
        "A_I = np.zeros(len(I))\n",
        "print(f'Q: {Q}, {len(Q)}')\n",
        "print(f'A: {A}, {len(A)}')\n",
        "print(f'I: {I}, {len(I)}')"
      ],
      "metadata": {
        "id": "NnEHO8tZQJa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f19f40-5031-4417-b433-a1c83be88d51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mà_thôi', 'tuy_có', 'đâu_như', 'quay_bước', 'hỏi_lại', 'khẳng_định', 'giờ_này', 'ren_rén', 'một_cơn', 'ủa', 'chợt', 'tốt_bộ', 'tuổi_tôi', 'mới_hay', 'hơn', 'để_lòng', 'vừa_qua', 'thêm_vào', 'ào_vào', 'nghe_không', 'cái_đã', 'bây_nhiêu', 'cha_chả', 'tự_ý', 'cái_đó', 'không_tính', 'chưa_kể', 'phía', 'tính_từ', 'như_ai', 'anh_ấy', 'lâu_lâu', 'nhất_loạt', 'khó_khăn', 'vùng', 'dù_rằng', 'sự_việc', 'gây_cho', 'phải_như', 'mạnh', 'bước', 'dễ_sử_dụng', 'nhanh_lên', 'bất_quá', 'bởi_vì', 'cả_ngày', 'ô_hay', 'cho_đến', 'ba_ba', 'dưới', 'dạ_bán', 'gặp', 'tránh_xa', 'thật_là', 'vài_điều', 'một_cách', 'ba_cùng', 'vượt_quá', 'vô_kể', 'nghe_được', 'và', 'ô_kê', 'vì', 'nhận_nhau', 'tên', 'riu_ríu', 'không_kể', 'lời_nói', 'trước_đây', 'phải_chi', 'gần_bên', 'chỉ_chính', 'cả_tin', 'nhất_mực', 'cơ_chỉ', 'cao_thế', 'xuống', 'quan_tâm', 'ông_từ', 'mỗi_lần', 'xử_lý', 'là_ít', 'gì_gì', 'quả', 'chú_khách', 'quay_số', 'qua_đi', 'thực_vậy', 'hơn_là', 'làm_mất', 'bỏ_quá', 'nặng', 'dạ_con', 'gặp_khó_khăn', 'các_cậu', 'bằng_được', 'đang_thì', 'để_đến_nỗi', 'nghe_đâu', 'nước', 'trả_của', 'gây_thêm', 'tới_mức', 'ừ_ào', 'trong_đó', 'tôi', 'thanh_thanh', 'thường_đến', 'tò_te', 'nền', 'nhỡ_ra', 'từng', 'tù_tì', 'phải', 'phăn_phắt', 'cái_gì', 'phía_trước', 'mọi_giờ', 'trước_khi', 'tiện_thể', 'lên_số', 'đến_nơi', 'cách_nhau', 'nước_quả', 'thấy_tháng', 'ấy', 'chùn_chùn', 'ngay_khi', 'nhìn', 'là_phải', 'một_vài', 'đại_nhân', 'hơn_trước', 'chúng_ta', 'ăn_tay', 'vậy_ư', 'không_bán', 'theo', 'biết_mình', 'với_nhau', 'ý_hoặc', 'cuối_cùng', 'đầy_năm', 'bấy_chừ', 'cụ_thể', 'tỏ_ra', 'vèo_vèo', 'con_nhà', 'cơ', 'ông', 'vài_nơi', 'tránh_tình_trạng', 'ở_vào', 'làm_tin', 'thuộc_lại', 'thế_thường', 'ngôi_nhà', 'ngồi_bệt', 'hiểu', 'cho_đang', 'nhìn_nhận', 'tới_thì', 'chuyện', 'ra', 'bỏ_lại', 'vừa', 'hãy_còn', 'chứ_lại', 'thuần', 'thêm_giờ', 'ắt_hẳn', 'ra_đây', 'do_đó', 'xoẹt', 'gì', 'giữa_lúc', 'giá_trị_thực_tế', 'coi_mòi', 'ái', 'không_có', 'ông_tạo', 'sự_thế', 'còn_thời_gian', 'nhận_họ', 'tự_vì', 'đều_đều', 'á', 'à', 'xin', 'trển', 'nếu_thế', 'ý', 'tạo_ra', 'nhưng', 'đưa_ra', 'nhằm_để', 'đến_lúc', 'ôi_chao', 'sáng', 'đây_này', 'quá_mức', 'cách', 'cơ_cùng', 'làm_ra', 'khỏi', 'ra_ngôi', 'rén', 'lại_bộ', 'như_thường', 'nói_ý', 'đến_thì', 'lần_trước', 'bán', 'để_lại', 'dạ_dài', 'bác', 'thiếu_gì', 'thì_thôi', 'quá_thì', 'trên_bộ', 'song_le', 'rồi_sao', 'bấy_giờ', 'mức', 'đưa_chuyện', 'nhà_chung', 'rõ_thật', 'răng_răng', 'sất', 'ai_ai', 'tính_phỏng', 'thì_phải', 'chung_cục', 'không_cứ', 'kể_cả', 'qua_tay', 'nhận_làm', 'thếch', 'hơn_nữa', 'như_không', 'vẫn', 'chốc_chốc', 'chẳng_phải', 'muốn', 'thực_tế', 'thế_nào', 'trước_hết', 'người_người', 'bắt_đầu_từ', 'ra_vào', 'tức_thì', 'kể_như', 'thường_thôi', 'thậm', 'thực_sự', 'do', 'cũng_nên', 'vung_thiên_địa', 'vào_đến', 'chưa', 'ngày_tháng', 'làm_tăng', 'trệu_trạo', 'tốt', 'ngay_tức_khắc', 'bất_tử', 'bỏ_bà', 'nhà_ngươi', 'mang_nặng', 'nhằm_lúc', 'đành_đạch', 'tất_cả', 'nhất_luật', 'điểm', 'vùng_lên', 'khó_mở', 'từ_thế', 'không_điều_kiện', 'sáng_thế', 'thỏm', 'bắt_đầu', 'phải_chăng', 'gần', 'người_nghe', 'hơn_cả', 'có_ăn', 'trước_kia', 'họ_xa', 'trong', 'ở_đây', 'dễ_như_chơi', 'hãy', 'ăn_hết', 'được', 'dùng_cho', 'tấn', 'mọi', 'nếu_mà', 'ba_ngôi', 'đâu', 'con', 'nước_bài', 'người', 'hết_của', 'gần_như', 'những_như', 'bây_bẩy', 'ở_lại', 'nói_lên', 'cần_số', 'vẫn_thế', 'hết_ý', 'quận', 'chọn_ra', 'sang_tay', 'tênh', 'lấy_thêm', 'nghĩ_tới', 'tuy_vậy', 'tạo_điều_kiện', 'chuyển_đạt', 'tanh', 'đại_để', 'thì', 'giảm_thế', 'thà', 'ra_điều', 'thanh_điểm', 'mất', 'vung_tán_tàn', 'nói_qua', 'cuối', 'chợt_nhìn', 'cuốn', 'chúng', 'đến_lời', 'thường_bị', 'bạn', 'vài_nhà', 'nên_người', 'với', 'khách', 'chứ_lị', 'từng_thời_gian', 'ào', 'từ_đó', 'tính_người', 'nhằm', 'nếu_cần', 'sáng_ý', 'chọn', 'từ_tại', 'bằng_nào', 'toà', 'ạ_ơi', 'do_vậy', 'cả_nghe', 'có_ý', 'đánh_đùng', 'ăn_quá', 'cho_đến_khi', 'đưa_tới', 'tăm_tắp', 'nhận', 'trời_đất_ơi', 'có_họ', 'nhìn_chung', 'bỗng_dưng', 'sang_năm', 'sì', 'vào_vùng', 'chịu_ăn', 'hay', 'vì_rằng', 'bài', 'trỏng', 'tăng_thế', 'thỉnh_thoảng', 'thích_cứ', 'làm_đúng', 'bấy_chầy', 'không_cần', 'từ_ái', 'trong_ngoài', 'phải_cách', 'mới_rồi', 'tính', 'vâng_ý', 'a_lô', 'quả_vậy', 'ngọn', 'nghĩ_lại', 'ngọt', 'ngày_ngày', 'cụ_thể_là', 'người_khách', 'lượng', 'nói_chung', 'nhà_việc', 'tin_thêm', 'khoảng_cách', 'bà', 'nào_hay', 'bộ_điều', 'giảm_chính', 'thật_ra', 'có_nhiều', 'thật_quả', 'chao_ôi', 'ít_có', 'sớm_ngày', 'lâu', 'bập_bõm', 'cao_thấp', 'ngay_lúc_này', 'ra_chơi', 'thế_thôi', 'chỉ_tên', 'dẫu_mà', 'rất_lâu', 'bấy_lâu', 'chắc_ăn', 'như_sau', 'bán_thế', 'thích_ý', 'tuy_rằng', 'đây_đó', 'không_dùng', 'vị_trí', 'tăng_giảm', 'tạo_nên', 'cá_nhân', 'ngoài', 'vả_chăng', 'em_em', 'đúng_ra', 'làm', 'ngồi', 'tất_tật', 'tốt_mối', 'ngõ_hầu', 'ra_lời', 'không_phải_không', 'lại_làm', 'lần_sau', 'khi', 'dễ_thấy', 'làm_lấy', 'áng_như', 'trong_vùng', 'tin', 'nhất_tâm', 'giảm_thấp', 'không_ngoài', 'biết_đâu', 'đều_bước', 'theo_tin', 'đâu_có', 'thiếu', 'cậu', 'nói', 'ngày_này', 'nóc', 'ô_kìa', 'chăn_chắn', 'nào_phải', 'mọi_nơi', 'đáng_số', 'ờ_ờ', 'ừ_thì', 'xuất_hiện', 'chứ_sao', 'dễ_nghe', 'đang', 'trả_ngay', 'nước_xuống', 'đến_xem', 'ối_giời', 'phía_bạn', 'cùng_cực', 'những_khi', 'đánh_giá', 'ba_họ', 'dì', 'hay_sao', 'không_ai', 'nên_làm', 'dù', 'tự_tính', 'veo', 'nhớ_bập_bõm', 'từng_ấy', 'nếu_có', 'cơ_mà', 'để_giống', 'suýt', 'quá_tin', 'của', 'bất_cứ', 'chị_bộ', 'vậy', 'biết_đâu_đấy', 'từ_nay', 'có_vẻ', 'kể_tới', 'đầy', 'nhìn_lại', 'xuất_kỳ_bất_ý', 'riêng', 'lấy_xuống', 'điểm_gặp', 'đại_loại', 'biết_chừng_nào', 'tọt', 'thôi', 'cho_tới', 'bệt', 'biết_chắc', 'sốt_sột', 'thật_lực', 'tại_đó', 'chịu_lời', 'chưa_cần', 'rứa', 'nhỏ', 'nghĩ_đến', 'giữ_ý', 'nhỉ', 'nhờ', 'nhớ', 'nức_nở', 'nói_rõ', 'vậy_nên', 'thanh_không', 'cứ_việc', 'ở_đó', 'nói_đến', 'thường_tại', 'vài_người', 'có_chăng_là', 'tại_tôi', 'lại_quả', 'từng_cái', 'điều', 'dùng_đến', 'cách_bức', 'cho_ăn', 'đâu_nào', 'nhà_ngoài', 'chứ_còn', 'mối', 'chết_tiệt', 'thời_điểm', 'ắt_là', 'đáng_lý', 'tà_tà', 'ăn_sáng', 'đáng_lí', 'bất_giác', 'lên_xuống', 'căn_cắt', 'hết_chuyện', 'có_nhà', 'như_thế', 'cao', 'dành_dành', 'tự_khi', 'gây', 'có_thể', 'lên_mạnh', 'ngay', 'phải_khi', 'ông_ổng', 'xiết_bao', 'vào', 'vài', 'nhờ_nhờ', 'phè', 'vào_gặp', 'rồi', 'điều_kiện', 'ví_thử', 'ngồi_trệt', 'mang_mang', 'thế_là', 'ít_thôi', 'ra_sao', 'khó_biết', 'đặt_ra', 'nhiên_hậu', 'nghe_đâu_như', 'lúc_lâu', 'đâu_cũng', 'đến_thế', 'ứ_ừ', 'chung_cuộc', 'âu_là', 'tạo_cơ_hội', 'nó', 'à_này', 'so', 'bởi_vậy', 'nhằm_vào', 'thời_gian_tính', 'thấp_thỏm', 'càng_càng', 'lớn_nhỏ', 'giờ_đến', 'có_điều_kiện', 'tốt_hơn', 'phải_lời', 'bản', 'giờ_lâu', 'ở_năm', 'dùng', 'nghỉm', 'cả', 'chùn_chũn', 'ái_chà', 'chịu', 'giống', 'quan_trọng_vấn_đề', 'đến_khi', 'hay_đâu', 'lòng_không', 'em', 'nào_đó', 'đến_bao_giờ', 'bất_đồ', 'tấn_tới', 'nghiễm_nhiên', 'ứ_hự', 'rất', 'lại_giống', 'làm_nên', 'ngăn_ngắt', 'lấy_làm', 'cật_sức', 'khác_xa', 'xệp', 'cô_tăng', 'nhớ_ra', 'nơi_nơi', 'tăng_cấp', 'một_ít', 'nếu', 'mọi_người', 'lại_còn', 'phần', 'gây_ra', 'tênh_tênh', 'biết_trước', 'thiếu_điểm', 'chiếc', 'chắc_vào', 'như_thể', 'sau_nữa', 'tựu_trung', 'ai_nấy', 'nếu_được', 'xa', 'thường_khi', 'giữ_lấy', 'bởi_chưng', 'nếu_như', 'của_ngọt', 'dùng_hết', 'trực_tiếp_làm', 'sở_dĩ', 'lớn_lên', 'bởi_thế_cho_nên', 'điểm_đầu_tiên', 'ấy_là', 'quay', 'ối_giời_ơi', 'một', 'không', 'cùng', 'thà_là', 'dưới_nước', 'có_chuyện', 'ông_ấy', 'oai_oái', 'chứ_không_phải', 'việc_gì', 'nói_khó', 'ngay_thật', 'sao', 'bội_phần', 'anh', 'có_dễ', 'xăm_xắm', 'thêm_chuyện', 'giống_như', 'trong_khi', 'sau', 'bỏ_ra', 'ngày_qua', 'trước_tuổi', 'xa_cách', 'rón_rén', 'bây_giờ', 'không_chỉ', 'hết_cả', 'buổi_làm', 'sáng_ngày', 'chúng_tôi', 'hay_nói', 'lấy_lý_do', 'ngay_tức_thì', 'này_nọ', 'thuần_ái', 'trong_số', 'bỏ_không', 'có_thế', 'thuộc_cách', 'căn_tính', 'sang_sáng', 'lại_cái', 'nhân_tiện', 'xa_nhà', 'khó_làm', 'bởi_thế', 'nhiều_ít', 'buổi_ngày', 'quả_thế', 'thực_hiện', 'thím', 'chăng_nữa', 'chú', 'đặt', 'chú_mình', 'cho_nên', 'ớ', 'chung_qui', 'cấp_số', 'vụt', 'chung_quy', 'duy_có', 'tại_sao', 'nặng_mình', 'biết_đâu_chừng', 'làm_dần_dần', 'đến_điều', 'bất_chợt', 'ăn_chịu', 'ở_được', 'ồ_ồ', 'thốc_tháo', 'vì_vậy', 'nói_toẹt', 'thật_thà', 'tháng_năm', 'ô_hô', 'nói_nhỏ', 'dùng_làm', 'tuy', 'đã_lâu', 'sau_cuối', 'từ_căn', 'lúc_đó', 'chí_chết', 'bất_kỳ', 'ăn_riêng', 'giống_nhau', 'làm_lòng', 'bất_kể', 'đã_không', 'bỗng_đâu', 'chịu_chưa', 'mang', 'lần_nào', 'ít_hơn', 'giữ', 'thái_quá', 'thộc', 'đưa_tay', 'thật_tốt', 'rằng', 'không_gì', 'rồi_thì', 'rằng_là', 'giờ', 'lấy_để', 'quá', 'còn_nữa', 'khác', 'tại_nơi', 'ít_ra', 'tất_thảy', 'chăng_chắc', 'dẫu_sao', 'dần_dà', 'lời_chú', 'khác_khác', 'ít_lâu', 'phía_sau', 'cuối_điểm', 'khoảng', 'chỉ_có', 'xem_ra', 'bỏ_mẹ', 'tránh_ra', 'nhìn_thấy', 'mang_lại', 'cứ', 'thấp_cơ', 'mình', 'mỗi', 'cùng_ăn', 'xăm_xăm', 'sau_sau', 'hay_là', 'đưa_cho', 'thường_xuất_hiện', 'sao_đang', 'đã_hay', 'từng_giờ', 'phần_lớn', 'nhân_dịp', 'giữa', 'tháng_tháng', 'nhờ_đó', 'phần_nhiều', 'nghĩ_xa', 'đáng', 'có_tháng', 'chết_nỗi', 'cũng', 'bị_chú', 'có_phải', 'phót', 'nhận_ra', 'phóc', 'làm_tại', 'đã_thế', 'tạo', 'trong_mình', 'tại', 'sắp_đặt', 'lấy_ráo', 'nhờ_chuyển', 'biết_bao', 'ra_bài', 'thốt_nhiên', 'ra_lại', 'làm_vì', 'hỏi', 'giờ_đi', 'vượt', 'do_vì', 'lấy_ra', 'về_sau', 'tăng', 'cụ_thể_như', 'thành_thử', 'thường_hay', 'bằng_như', 'tông_tốc', 'đều', 'nhìn_theo', 'ăn_trên', 'bỏ', 'phần_sau', 'nhất_định', 'chưa_từng', 'tắp_tắp', 'mà_vẫn', 'bớ', 'bộ', 'thi_thoảng', 'nhanh', 'ra_gì', 'đúng_với', 'tất_cả_bao_nhiêu', 'khi_trước', 'như_trên', 'ơi', 'cô', 'chầm_chập', 'tha_hồ', 'chính_thị', 'ngày_nào', 'có_khi', 'có', 'nhận_việc', 'choa', 'ở_như', 'tên_chính', 'thục_mạng', 'làm_ngay', 'không_cùng', 'sử_dụng', 'chỉn', 'bởi_tại', 'không_có_gì', 'quá_bộ', 'bước_tới', 'vạn_nhất', 'hỏi_xem', 'việc', 'như_là', 'khá_tốt', 'quá_đáng', 'thường_sự', 'cây_nước', 'trước_ngày', 'bập_bà_bập_bõm', 'đâu_đó', 'được_cái', 'ráo_trọi', 'nhất_sinh', 'ngồi_sau', 'con_dạ', 'từ_tính', 'sa_sả', 'tại_đâu', 'càng_hay', 'lần_sang', 'bỏ_cuộc', 'tại_đây', 'nghe_thấy', 'nghĩ', 'ra_ý', 'trong_này', 'mở_ra', 'ai', 'ráo_cả', 'ngày_xưa', 'tình_trạng', 'xem_số', 'phải_không', 'tháng', 'thốt_thôi', 'đặt_mức', 'nữa_rồi', 'bỗng_nhiên', 'đặt_làm', 'vừa_vừa', 'không_phải', 'nói_ra', 'á_à', 'người_hỏi', 'vậy_thì', 'lời', 'tốt_ngày', 'có_người', 'chị_ấy', 'ái_dà', 'phỉ_phui', 'chính_là', 'ý_da', 'bên', 'lấy_vào', 'ngày_ấy', 'đáng_kể', 'cho_rằng', 'rồi_đây', 'chớ_chi', 'còn_về', 'bỏ_cha', 'nhưng_mà', 'vượt_khỏi', 'phía_trên', 'ở_trên', 'lớn', 'lúc_ấy', 'thoạt_nhiên', 'chung_ái', 'phải_tay', 'bỗng_thấy', 'nhất_nhất', 'nhất_quyết', 'bỏ_việc', 'để_được', 'nghe_lại', 'bằng_không', 'trếu_tráo', 'có_ngày', 'đặt_để', 'sang', 'thì_giờ', 'bài_bỏ', 'lại_người', 'tiếp_theo', 'nhất_tề', 'lượng_số', 'qua_lại', 'xảy_ra', 'hiện_nay', 'chính_giữa', 'mang_về', 'thật', 'chứ_như', 'chợt_nghe', 'hỗ_trợ', 'đến_ngày', 'làm_tôi', 'mọi_việc', 'nói_đủ', 'được_lời', 'lượng_từ', 'thật_vậy', 'dở_chừng', 'dễ', 'phải_lại', 'thời_gian', 'sao_bản', 'vì_thế', 'từ_loại', 'tháng_ngày', 'dữ', 'vừa_rồi', 'lần_theo', 'chỉ_là', 'chắc_hẳn', 'họ', 'phỏng_như', 'bông', 'loại', 'vâng_dạ', 'vấn_đề', 'sáng_rõ', 'tuy_nhiên', 'gồm', 'phương_chi', 'sắp', 'gần_đây', 'hay_tin', 'hay_làm', 'nặng_căn', 'cơ_dẫn', 'cần', 'dễ_đâu', 'dù_cho', 'nghe_trực_tiếp', 'cật_lực', 'mà_cả', 'số_thiếu', 'chơi_họ', 'ngày_rày', 'đủ_dùng', 'ăn_chung', 'thật_chắc', 'có_điều', 'bấy_nay', 'thậm_cấp', 'ví_phỏng', 'cho_nhau', 'thuộc_bài', 'nữa_là', 'nhớ_lại', 'thế_à', 'vốn_dĩ', 'chưa_có', 'giá_trị', 'ắt_phải', 'sao_vậy', 'bất_quá_chỉ', 'thế_chuẩn_bị', 'lượng_cả', 'không_bao_lâu', 'mọi_lúc', 'thế_đó', 'bay_biến', 'về', 'nhón_nhén', 'đưa_về', 'dào', 'còn', 'làm_như', 'ở', 'vô_luận', 'ờ', 'tự_lượng', 'ồ', 'luôn_cả', 'toẹt', 'ừ', 'cứ_điểm', 'ử', 'chưa_bao_giờ', 'dạ', 'chịu_tốt', 'tăng_thêm', 'bằng_người', 'phỏng_theo', 'có_đâu', 'lâu_các', 'tuốt_tuồn_tuột', 'riêng_từng', 'tỏ_vẻ', 'cao_số', 'như', 'đại_phàm', 'lên_cơn', 'đủ_điểm', 'thế_nên', 'lần', 'trả_trước', 'là_nhiều', 'tắp', 'quay_đi', 'a_ha', 'xăm_xúi', 'lòng', 'tắp_lự', 'phải_người', 'bỏ_mình', 'chú_dẫn', 'đủ_điều', 'khoảng_không', 'đã_vậy', 'yêu_cầu', 'câu_hỏi', 'cho_tới_khi', 'nước_đến', 'để', 'chính_điểm', 'tìm_hiểu', 'ăn_hỏi', 'dẫu', 'ngươi', 'gần_hết', 'như_tuồng', 'khỏi_nói', 'tìm_ra', 'bất_thình_lình', 'trực_tiếp', 'mới', 'xa_gần', 'xa_tanh', 'chứ_gì', 'ngoải', 'dài_ra', 'bao_nả', 'này', 'trên_dưới', 'số_cụ_thể', 'nói_là', 'nào', 'luôn', 'nước_nặng', 'khác_gì', 'cả_đến', 'đó_đây', 'thay_đổi', 'gần_ngày', 'phía_trong', 'như_thế_nào', 'tạo_ý', 'buổi', 'quay_lại', 'khá', 'có_cơ', 'cảm_ơn', 'dễ_ngươi', 'khó', 'như_chơi', 'phải_giờ', 'tuổi', 'tốc_tả', 'răng', 'nhờ_có', 'rồi_xem', 'ngoài_xa', 'chưa_tính', 'được_nước', 'thình_lình', 'phía_bên', 'sau_đó', 'lại_ăn', 'sao_bằng', 'quá_bán', 'nguồn', 'phụt', 'nhất_thì', 'cùng_nhau', 'nên_chi', 'nghe_nhìn', 'lấy_được', 'cho_chắc', 'bỏ_riêng', 'ơi_là', 'lên_cao', 'mới_đây', 'thế_thì', 'bằng_vào', 'cuộc', 'kể_từ', 'bất_kì', 'đầu_tiên', 'trả_lại', 'ngôi_thứ', 'ít_nhất', 'cách_không', 'nhằm_khi', 'chung_quy_lại', 'cu_cậu', 'xuất_kì_bất_ý', 'nhất_thiết', 'phải_biết', 'nghen', 'đưa_đến', 'kể', 'đâu_phải', 'dễ_gì', 'đến_gần', 'quả_là', 'đến_nay', 'cao_xa', 'thốt_nói', 'nghe_nói', 'bởi_nhưng', 'phè_phè', 'công_nhiên', 'đặt_trước', 'bước_đi', 'lấy_cả', 'chứ_không', 'tuần_tự', 'thích_tự', 'mà_lại', 'để_mà', 'ạ', 'với_lại', 'đến_giờ', 'ngày_càng', 'bản_bộ', 'dẫu_rằng', 'ừ_ừ', 'nói_bông', 'như_quả', 'bèn', 'về_phần', 'chậc', 'tìm_việc', 'làm_được', 'lúc_đến', 'có_đáng', 'mọi_sự', 'vâng', 'úi_chà', 'khác_nhau', 'tự_ăn', 'ngay_từ', 'nhung_nhăng', 'khác_thường', 'số_người', 'khó_tránh', 'bỗng', 'cứ_như', 'bởi_đâu', 'một_khi', 'tính_cách', 'tiếp_đó', 'qua_khỏi', 'mất_còn', 'là_thế_nào', 'giống_người', 'ông_nhỏ', 'hoặc_là', 'vung_tàn_tán', 'cũng_được', 'thanh_ba', 'con_tính', 'chắc_chắn', 'vị_tất', 'ngày_nọ', 'bên_bị', 'cóc_khô', 'ngay_bây_giờ', 'thì_là', 'làm_riêng', 'chứ_ai', 'tuy_đã', 'đâu_đây', 'trừ_phi', 'lý_do', 'đâu_đâu', 'ôi_thôi', 'nhiều', 'quá_trình', 'ăn_chắc', 'chuyển_tự', 'duy', 'ngày_giờ', 'khi_nên', 'chắc_dạ', 'nên_chăng', 'tuốt_luốt', 'dành', 'không_nhận', 'văng_tê', 'cả_thể', 'tấm_các', 'nói_thêm', 'thà_rằng', 'đưa', 'xoét', 'ráo', 'à_ơi', 'thích_thuộc', 'đặc_biệt', 'ngày_xửa', 'chưa_dùng', 'duy_chỉ', 'phỏng', 'phía_dưới', 'rồi_ra', 'thế_lại', 'thường_tính', 'bà_ấy', 'những_lúc', 'chành_chạnh', 'trước_đó', 'thứ_bản', 'số_là', 'lại_thôi', 'thoạt', 'giờ_đây', 'lại_nói', 'rõ', 'đủ_số', 'tha_hồ_chơi', 'từ_giờ', 'khó_chơi', 'quá_giờ', 'trở_thành', 'ngay_cả', 'ví_dù', 'sau_hết', 'cấp', 'bằng_cứ', 'ngay_lúc', 'ít_khi', 'đủ_nơi', 'bên_cạnh', 'lên_nước', 'chúng_mình', 'qua_thì', 'được_tin', 'đây', 'biết_việc', 'thực_hiện_đúng', 'tên_tự', 'làm_theo', 'nghe_rõ', 'mở', 'tột', 'rồi_sau', 'ăn_ngồi', 'vào_khoảng', 'lấy_có', 'thảo_hèn', 'cái_ấy', 'đến_nỗi', 'cực_lực', 'đủ', 'suýt_nữa', 'nói_phải', 'thậm_chí', 'cho_biết', 'hơn_hết', 'mợ', 'buổi_mới', 'tại_vì', 'từng_phần', 'thứ', 'năm_tháng', 'rốt_cuộc', 'nói_thật', 'ơ_kìa', 'nước_ăn', 'thì_ra', 'hầu_hết', 'lâu_nay', 'ngày_cấp', 'bài_bác', 'như_trước', 'sao_cho', 'loại_từ', 'phải_rồi', 'ba', 'đều_nhau', 'trả', 'lúc_sáng', 'ớ_này', 'bỗng_không', 'mọi_thứ', 'cây', 'vừa_lúc', 'lấy', 'vừa_khi', 'phốc', 'chớ_không', 'người_mình', 'bằng_nhau', 'nghe_hiểu', 'tại_lòng', 'nhé', 'không_những', 'cả_nhà', 'nữa_khi', 'lần_lần', 'bị', 'rày', 'sau_đây', 'tay_quay', 'bằng', 'con_con', 'nghe_ra', 'sẽ_hay', 'thích', 'chủn', 'than_ôi', 'càng', 'vài_tên', 'bị_vì', 'ối_dào', 'hoặc', 'xềnh_xệch', 'không_để', 'ra_tay', 'nặng_về', 'veo_veo', 'sau_này', 'cả_ăn', 'coi_bộ', 'ý_chừng', 'làm_bằng', 'vâng_vâng', 'cao_ráo', 'thanh_tính', 'không_hay', 'lại_đây', 'xin_gặp', 'nói_trước', 'phần_nào', 'tránh', 'rén_bước', 'đơn_vị', 'nay', 'thửa', 'tuốt_tuột', 'tột_cùng', 'oái', 'quá_lời', 'lúc_trước', 'lấy_số', 'đưa_em', 'khó_thấy', 'ít_nhiều', 'ở_nhờ', 'cùng_với', 'nọ', 'khi_khác', 'tối_ư', 'nớ', 'lần_này', 'dầu_sao', 'làm_gì', 'bởi_ai', 'gặp_phải', 'hỏi_xin', 'nhất', 'chẳng_nữa', 'rõ_là', 'đúng', 'ai_đó', 'xa_tắp', 'căn_cái', 'ba_bản', 'tấm_bản', 'cũng_vậy_thôi', 'cùng_tột', 'nhà_tôi', 'bỗng_nhưng', 'khó_nói', 'quá_tuổi', 'nấy', 'ngay_khi_đến', 'ổng', 'vâng_chịu', 'vở', 'sẽ', 'bấy_lâu_nay', 'tuy_thế', 'tự_tạo', 'điều_gì', 'lúc_này', 'mỗi_một', 'ngồi_không', 'mỗi_người', 'lúc_nào', 'qua_ngày', 'gây_giống', 'bỗng_chốc', 'hay_biết', 'cao_răng', 'tuyệt_nhiên', 'giảm', 'thúng_thắng', 'dạ_dạ', 'vả_lại', 'nhau', 'vừa_mới', 'vùng_nước', 'nói_lại', 'ngọn_nguồn', 'trên', 'cao_sang', 'ngôi', 'chung_cho', 'sì_sì', 'năm', 'đảm_bảo', 'thế', 'sẽ_biết', 'ngộ_nhỡ', 'dễ_khiến', 'thậm_từ', 'tự', 'cả_nghĩ', 'riệt', 'ăn_về', 'rồi_nữa', 'lần_khác', 'chưa_chắc', 'tìm_cách', 'cả_người', 'thương_ôi', 'tha_hồ_ăn', 'bấy_nhiêu', 'ít_biết', 'chắc', 'hay_hay', 'tất_tần_tật', 'cha', 'tới_nơi', 'vậy_là', 'thế_sự', 'dạ_khách', 'cho', 'ào_ào', 'tanh_tanh', 'đến_hay', 'biết_bao_nhiêu', 'alô', 'bỏ_xa', 'thuộc_từ', 'lúc_đi', 'biết_được', 'chẳng_lẽ', 'chính', 'hết_rồi', 'tự_cao', 'cho_hay', 'vài_ba', 'chớ_gì', 'nếu_vậy', 'có_chăng', 'cho_thấy', 'bản_thân', 'tay', 'thẩy', 'cho_được', 'khi_không', 'chuyển', 'hết_nói', 'có_ai', 'bán_cấp', 'cho_tin', 'ít_quá', 'bước_khỏi', 'là_vì', 'xuể', 'ba_tăng', 'bây_chừ', 'có_chứ', 'tăng_chúng', 'nữa', 'lúc', 'biết_mấy', 'sau_chót', 'từ_điều', 'ầu_ơ', 'đạt', 'quan_trọng', 'cho_rồi', 'như_ý', 'bất_ngờ', 'khó_nghe', 'ít', 'nào_cũng', 'cô_ấy', 'nhược_bằng', 'chết_thật', 'cơn', 'thanh_chuyển', 'quá_tay', 'thoắt', 'từng_đơn_vị', 'đầy_phè', 'bất_luận', 'lấy_lại', 'ăn_người', 'trệt', 'đến', 'thế_mà', 'thảo_nào', 'quá_ư', 'làm_sao', 'biết_thế', 'ơ', 'nước_cùng', 'đáng_lẽ', 'thường', 'mở_mang', 'chung', 'rút_cục', 'đến_tuổi', 'ngày_đến', 'nhớ_lấy', 'nhà_làm', 'bởi', 'hết_ráo', 'nhận_được', 'tránh_khỏi', 'cho_về', 'áng', 'những', 'ăn_cuộc', 'ngoài_này', 'tít_mù', 'điểm_chính', 'nhóm', 'sau_cùng', 'cách_đều', 'bức', 'qua', 'tới', 'tin_vào', 'nhận_thấy', 'nói_với', 'vô_hình_trung', 'ráo_nước', 'đang_tay', 'cô_mình', 'về_không', 'đến_cùng', 'đây_rồi', 'nhất_là', 'chưa_dễ', 'úi_dào', 'tới_gần', 'tốt_bạn', 'thốt', 'thốc', 'đã_là', 'làm_tắp_lự', 'đúng_ngày', 'ăn', 'qua_chuyện', 'chú_mày', 'nghĩ_ra', 'trước_nay', 'nào_là', 'chu_cha', 'chẳng_những', 'thật_sự', 'dù_dì', 'tìm', 'vậy_mà', 'để_cho', 'chắc_lòng', 'ví_bằng', 'xoành_xoạch', 'vèo', 'đó', 'sự', 'rích', 'làm_thế_nào', 'bản_riêng', 'bao_nhiêu', 'đã', 'đến_cùng_cực', 'trước_tiên', 'quả_thật', 'đã_đủ', 'như_vậy', 'số', 'quá_nhiều', 'nói_riêng', 'cao_lâu', 'nên_tránh', 'chuẩn_bị', 'một_số', 'không_được', 'cho_đến_nỗi', 'về_tay', 'bán_dạ', 'bằng_ấy', 'phỏng_tính', 'nhất_đán', 'gì_đó', 'tiếp_tục', 'trước', 'dù_sao', 'tên_cái', 'bao_giờ', 'có_số', 'mà_không', 'lấy_sau', 'cơ_chừng', 'chăng', 'theo_bước', 'liên_quan', 'dài_lời', 'úi', 'về_nước', 'những_ai', 'thêm', 'dễ_sợ', 'cổ_lai', 'béng', 'để_phần', 'không_đầy', 'phứt', 'cơ_hồ', 'dễ_dùng', 'nên', 'toé_khói', 'phần_việc', 'dữ_cách', 'tuổi_cả', 'cả_thảy', 'còn_như', 'bỏ_nhỏ', 'nơi', 'hay_nhỉ', 'để_không', 'mỗi_ngày', 'cả_năm', 'xin_vâng', 'chia_sẻ', 'có_được', 'theo_như', 'hay_không', 'thứ_đến', 'bởi_sao', 'ít_thấy', 'lại_nữa', 'bấy', 'amen', 'chính_bản', 'trong_lúc', 'phắt', 'nghe_tin', 'lâu_ngày', 'đối_với', 'thanh', 'ngoài_ra', 'ít_nữa', 'nào_đâu', 'dù_gì', 'cùng_chung', 'thôi_việc', 'cần_cấp', 'bản_ý', 'phỏng_nước', 'lần_tìm', 'nghe_chừng', 'nói_tốt', 'thường_số', 'người_khác', 'bộ_thuộc', 'bên_có', 'bằng_nấy', 'dễ_ăn', 'cái', 'không_biết', 'các', 'tên_họ', 'bao_lâu', 'những_muốn', 'cùng_tuổi', 'số_cho_biết', 'nói_xa', 'nhanh_tay', 'đặt_mình', 'khó_nghĩ', 'trước_sau', 'từ_từ', 'nhỏ_người', 'gần_xa', 'tấm', 'tức_tốc', 'từ_ấy', 'buổi_sớm', 'đúng_tuổi', 'chơi', 'dài', 'mỗi_lúc', 'luôn_luôn', 'nhiệt_liệt', 'không_bao_giờ', 'thấp_xuống', 'pho', 'hoàn_toàn', 'chung_nhau', 'lên', 'chung_chung', 'chắc_người', 'dẫn', 'không_khỏi', 'một_lúc', 'ngày', 'bỏ_mất', 'trước_nhất', 'lúc_khác', 'lên_đến', 'xa_xả', 'so_với', 'xem', 'trong_ấy', 'thế_ra', 'ngay_lập_tức', 'phải_cái', 'ắt_thật', 'nghe', 'dễ_thường', 'qua_lần', 'xa_xa', 'ư', 'vì_sao', 'lấy_giống', 'chớ', 'cô_quả', 'lên_ngôi', 'chị', 'như_nhau', 'chỉ', 'ắt', 'biết', 'chớ_kể', 'chớ_như', 'mở_nước', 'khác_nào', 'chứ', 'nước_lên', 'cơ_hội', 'nhà', 'thực_ra', 'họ_gần', 'làm_lại', 'ba_ngày', 'tìm_bạn', 'thấp', 'là_là', 'rồi_tay', 'chọn_bên', 'cũng_thế', 'thấy', 'số_phần', 'ra_bộ', 'từ', 'nhìn_xuống', 'tính_căn', 'khi_nào', 'vào_lúc', 'nhận_biết', 'căn', 'hiện_tại', 'từ_khi', 'ơ_hay', 'mà', 'phù_hợp', 'thuộc', 'tớ', 'nghe_như', 'chui_cha', 'sớm', 'ừ_nhé', 'đưa_tin', 'tuy_là', 'thoạt_nghe', 'ra_người', 'xem_lại', 'không_còn', 'người_nhận', 'tập_trung', 'vấn_đề_quan_trọng', 'nhà_khó', 'vì_chưng', 'vậy_ra', 'thành_ra', 'chúng_ông', 'cảm_thấy', 'xoẳn', 'rốt_cục', 'của_tin', 'tôi_con', 'những_là', 'số_loại', 'xon_xón', 'vô_vàn', 'từng_nhà', 'đồng_thời', 'gần_đến', 'đến_đâu', 'thay_đổi_tình_trạng', 'là_cùng', 'cũng_như', 'đến_cả', 'làm_cho', 'bển', 'bài_cái', 'nếu_không', 'lấy_thế', 'cũng_vậy', 'cấp_trực_tiếp', 'luôn_tay', 'là', 'không_thể', 'thường_thường', 'cần_gì', 'mọi_khi', 'đáo_để', 'ăn_làm', 'thanh_điều_kiện', 'đầy_tuổi', 'đưa_vào', 'đưa_xuống', 'bất_nhược', 'khiến', 'thời_gian_sử_dụng', 'cái_họ', 'hết', 'lại', 'thế_thế', 'dần_dần']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "Q: ['Các Trường đại học khác có ngành Công nghệ thông tin (CNTT), Trường ĐHBK chỉ có hai ngành: Khoa học Máy tính (KHMT) và ngành Kỹ thuật Máy tính (KTMT). Vậy hai ngành này có giống với ngành CNTT của các Trường ĐH khác không?'\n",
            " 'Khác nhau giữa ngành KHMT và KTMT?'\n",
            " 'Nếu ban đầu em học ngành KHMT, sau đó, em thấy không phù hợp, em có thể chuyển sang ngành KTMT được không?'\n",
            " 'Em muốn học làm robot, điều khiển từ xa các thiết bị trong gia đình thì em nên học ngành nào?'\n",
            " 'Học phí của ngành KHMT, KTMT?'\n",
            " 'Khi học xong ngành KHMT, KTMT, em có được đi dạy không?'\n",
            " 'Trường có Ký túc Xá không? Em có được ở KTX không?'\n",
            " 'Em học ngành KHMT ra Trường có việc làm không?'\n",
            " 'Trường có giới thiệu việc làm cho em không?'\n",
            " 'Em học ngành KTMT hoặc KHMT, em có thể đi du học được không?'\n",
            " 'Em ở quê, chưa được học viết chương trình, em có thể học được ngành KHMT không?'\n",
            " 'Trường có giới thiệu em miễn nghĩa vụ quân sự không?'\n",
            " 'Trường có cho em vay tiền đóng tiền học phí không?'\n",
            " 'Sau khi em ra Trường, em có được học tiếp lên cao nữa hay không?'\n",
            " 'Em học không giỏi lắm, em nên học ngành nào? (KHMT, KTMT)'\n",
            " 'Học phí có đắt không?'\n",
            " 'Em có nghe chương trình tiên tiến. Vậy chương trình tiên tiến là gì?'\n",
            " 'Em nghe bạn em nói, Trường ĐHBK có cơ sở ở Thủ Đức. Nếu em đăng ký học ngành KHMT, em học ở cơ sở nào?'\n",
            " 'Em thích làm web, em nên học ngành nào?'\n",
            " 'Học ngành KHMT, KTMT mất bao nhiêu năm?'\n",
            " 'Em nghe bạn em nói học ngành KHMT khó lắm, mà em học không giỏi môn vật lý, em học có được không?'\n",
            " 'Ở Trường em dưới quê, em chỉ có học word, excel, window. Vậy, em có học được ngành KTMT không?'\n",
            " 'Ngành KHMT và KTMT, ngành học nào dễ hơn.'\n",
            " 'Sau khi học 1 thời gian, em muốn chuyển ngành khác hoặc chuyển hình thức đào tạo thì có được phép không? Vd từ ngành KHMT sang ngành KTMT, vd từ chương trình chất lượng cao sang chương trình chính quy đại trà?'\n",
            " 'Khoa KH & KT Máy tính có đào tạo song ngành hay không?'\n",
            " 'Khoa KH & KT Máy tính có chương trình liên thông hay không?'\n",
            " 'Khoa KH & KT Máy tính có chương trình dành cho người vừa đi làm vừa đi học hay không? Thí sinh cần tham gia thi tuyển hay chỉ cần xét tuyển?'\n",
            " 'Ngành Kỹ thuật Máy tính là ngành học về vấn đề gì?'\n",
            " 'Sự khác biệt giữa ngành Kỹ thuật Máy tính và ngành Khoa học Máy tính ở trường Đại học Bách khoa – ĐHQG TPHCM là gì?'\n",
            " 'Sự khác biệt giữa Kỹ thuật Máy tính và Công nghệ thông tin là gì?'\n",
            " 'Có các chuyên ngành/hướng nào trong ngành Kỹ thuật Máy tính?'\n",
            " 'Có cần phải có kiến thức/kỹ năng gì để học được ngành KTMT?'\n",
            " 'Có thể học về trí tuệ nhân tạo trong ngành KTMT không?'\n",
            " 'Có thể học về an ninh mạng trong ngành KTMT không?'\n",
            " 'Có thể học về IoT trong ngành KTMT không?'\n",
            " 'Có thể học về hệ thống nhúng trong ngành KTMT không?'\n",
            " 'Có thể học về tính toán hiệu năng cao – điện toán đám mây trong ngành KTMT không?'\n",
            " 'Có thể học về thiết kế chip/thiết kế vi mạch trong ngành KTMT không?'\n",
            " 'Các thành tích nổi bật của SV ngành KTMT trong những năm qua là gì?'\n",
            " 'Nếu cần thêm thông tin hoặc cần tư vấn về ngành Kỹ thuật Máy tính thì liên hệ ở đâu?'\n",
            " 'Hồ sơ xét tuyển theo phương thức 2 bị sai nơi sinh thì phải làm sao?'\n",
            " 'Điểm xét tuyển theo phương thức 2 Ưu tiên xét tuyển có được cộng thêm điểm thưởng khi có các thành tích khác không ạ?'\n",
            " 'Em thi tổ hợp các môn Khoa học xã hội thì có xét tuyển được vào ngành Công nghệ Thông tin không ạ?'\n",
            " 'Hồ sơ xét tuyển theo phương thức 2 của em bị sai thông tin khu vực ưu tiên thì có cần nộp lại bộ hồ sơ khác không ạ?'\n",
            " 'Dạ cho em hỏi là nếu trong học kỳ, em đăng kí 28 chỉ mà chỉ đạt có 25 chỉ, em dự định sẽ đăng ký môn khác 3 chỉ trong HK hè để bù vào vậy thì có tính là em được phép đăng ký môn học của năm tiếp theo không ạ'\n",
            " 'Trong quá trình nhập thông tin em có ghi sai thông tin môn tiếng anh lớp 10 từ 8.0 thành 8.4 mong trường xem xét và sửa lại giúp em. Em cảm ơn'\n",
            " 'Trường có làm việc vào thứ 7 không ạ?'\n",
            " 'Làm sao để biết hồ sơ gửi đi đã hợp lệ hay chưa ạ?'\n",
            " 'Cho em hỏi thời gian công bố kết quả phương thức 1.1 Xét tuyển thẳng theo quy định của Bộ Giáo dục & Đào tạo và ĐHQG-HCM ạ?'\n",
            " 'Dạ cho em hỏi ngành logistic bên trường có xét theo khối C k ạ'\n",
            " 'Cho em hỏi công thức tính điểm phương thức 5 Xét tuyển kết hợp nhiều tiêu chí ạ?'\n",
            " 'KTX bách khoa ở quận 10 có gần trường không ạ?'\n",
            " 'Thầy cô ơi cho e hỏi là khi nào công bố điểm chuẩn phương thức utxt 2 ạ'\n",
            " 'Cho em hỏi còn đợt nộp hồ sơ cho chương trình đào tạo thạc sĩ phương thức tuyển thẳng nào không. Do em chưa chuẩn bị đủ hồ sơ nên đợt nộp ngày 16/6/2023 em không thể nộp kịp. Em mong được phản hồi. xin cám ơn admin'\n",
            " 'Cho em hỏi trường xét phương thức kết hợp 5 là vào ngày mấy ạ'\n",
            " 'Cho em hỏi học phí ngành khoa học máy tính chương trình giảng dạy bằng tiếng Anh của trường được không ạ?'\n",
            " 'Cho em hỏi là PT5 xét tuyển thì không có ĐGNL có đủ điều kiện xét không ạ'\n",
            " 'Cho em hỏi phương thức kết hợp khi nào mới có điểm chuẩn ạ'\n",
            " 'Dạ em là thí sinh chuẩn bị thi đại học năm nay, em có nguyện vọng vào Bách Khoa nhưng lúc tạo tài khoản trên mybk em bị quên mật khẩu thì giờ em phải làm sao đây ạ'\n",
            " 'Dạ cho em hỏi trọng số các tiêu chí điểm trong phương thức 5 là bao nhiêu ạ?'\n",
            " nan\n",
            " 'Khoa KH & KT Máy tính có chương trình dành cho người vừa đi làm vừa đi học hay không? Thí sinh cần tham gia thi tuyển hay chỉ cần xét tuyển?'], 62\n",
            "A: ['\\nTại ĐH Bách Khoa, Khoa KH & KT Máy tính, đào tạo 2 ngành Khoa học Máy tính và Kỹ thuật Máy tính. Từ khóa 2019, ngành Khoa học Máy tính bao gồm 6 chuyên ngành:\\n1) Khoa học Máy tính, \\n2) Công nghệ dữ liệu bảo mật & trí tuệ kinh doanh, \\n3) Công nghệ phần mềm, \\n4) Mật mã và an ninh mạng, \\n5) Trí tuệ nhân tạo và ứng dụng, \\n6) Xử lý ảnh và Thị giác máy tính. \\nNgành Kỹ thuật Máy tính bao gồm 3 chuyên ngành:\\n1) Kỹ thuật Máy tính, \\n2) Hệ thống tính toán hiện đại, \\n3) Internet vạn vật và an ninh mạng. \\nCó thể hiểu, Công nghệ Thông tin là tên gọi chung, chỉ 1 nhóm môn học mà trong quá trình học 1 trong 2 ngành kể trên, các em sẽ được cung cấp kiến thức về nó.\\n'\n",
            " '\\nKHMT:\\nNgành Khoa học Máy tính thuộc nhóm ngành Máy tính và Công nghệ thông tin. Mục tiêu của chương trình ngành Khoa học Máy tính là đào tạo ra những kỹ sư có chất lượng cao, có khả năng thiết kế, xây dựng và triển khai những hệ thống phần mềm đáp ứng nhu cầu trong nước và quốc tế. Kỹ sư tốt nghiệp ngành Khoa học Máy tính cũng được trang bị những kiến thức cần thiết để có thể học tiếp cao học và tiến sỹ trong lĩnh vực Máy tính và Công nghệ thông tin.\\n q\\nChương trình sẽ trang bị cho sinh viên kiến thức nền tảng thuộc lĩnh vực Máy tính và Công nghệ thông tin, kiến thức cốt lõi ngành Khoa học Máy tính, và kiến thức, công nghệ chuyên sâu của ngành như trí tuệ nhân tạo, bảo mật và an toàn máy tính, xử lý dữ liệu khối lượng lớn từ mạng Internet và các mạng xã hội, thiết kế và phát triển các ứng dụng cho các thiết bị di động và môi trường Web.\\nSau khi tốt nghiệp chương trình ngành Khoa học Máy tính của Trường Đại học Bách Khoa, các kỹ sư có thể đảm nhiệm nhiều công việc trong lĩnh vực Máy tính và Công nghệ thông tin như:\\n-       Thiết kế và xây dựng các phầm mềm máy tính cho các ngân hàng, các tổ chức tài chính, hành chính và thương mại, v.v.\\n-       Thiết kế và xây dựng các ứng dụng cho các thiết bị di động, ứng dụng thương mại điện tử trên nền Web, các trò chơi trên máy tính và thiết bị di động, v.v.\\n-       Quản trị và xây dựng các giải pháp đảm bảo an toàn cho các hệ thống máy tính và hệ thống mạng máy tính.\\n-       Làm việc trong các công ty gia công phần mềm cho các thị trường Mỹ, Nhật và Châu  u.\\n-       Tư vấn, thẩm định và phát triển các dự án, giải pháp công nghệ thông tin.\\nKTMT:\\nNgành Kỹ thuật Máy tính thuộc nhóm ngành Máy tính và Công nghệ thông tin. Mục tiêu của chương trình ngành Kỹ thuật Máy tính là đào tạo ra những kỹ sư có chất lượng cao, có khả năng thiết kế, xây dựng và triển khai những hệ thống phần mềm và phần cứng cho máy tính và các thiết bị điều khiển nhằm đáp ứng nhu cầu trong nước và quốc tế. Kỹ sư tốt nghiệp ngành Kỹ thuật Máy tính cũng được trang bị những kiến thức cần thiết để có thể học tiếp cao học và tiến sỹ trong lĩnh vực Máy tính và Công nghệ thông tin.\\n \\nChương trình sẽ trang bị cho sinh viên kiến thức nền tảng thuộc lĩnh vực Máy tính và Công nghệ thông tin, kiến thức cốt lõi ngành Kỹ thuật Máy tính, và kiến thức, công nghệ chuyên sâu của ngành như vi xử lý, vi điều khiển, thiết kế vi mạch, phần mềm nhúng, phần mềm cho các thiết bị điều khiển tự động, robot công nghiệp. \\nSau khi tốt nghiệp chương trình ngành Kỹ thuật Máy tính của Trường Đại học Bách Khoa, các kỹ sư có thể đảm nhiệm nhiều công việc trong lĩnh vực Máy tính và Công nghệ thông tin như:\\n-       Thiết kế và xây dựng các phầm mềm, phần cứng cho các thiết bị điều khiển tự động như các thiết bị điều khiển trong ô tô, thiết bị điện tử, thiết bị đọc mã vạch, robot công nghiệp, các dây chuyền công nghiệp.\\n-       Quản trị và xây dựng các giải pháp đảm bảo an toàn cho các hệ thống máy tính và mạng máy tính.\\n-       Làm việc trong các công ty gia công phần mềm cho các thị trường Mỹ, Nhật và Châu  u.\\n-       Tư vấn, thẩm định và phát triển các dự án, giải pháp công nghệ thông tin.\\n'\n",
            " '\\nSV được phép chuyển ngành nếu thỏa các điều kiện theo quy định học vụ.\\n'\n",
            " '\\nKỹ thuật máy tính là 1 lựa chọn phù hợp.\\n'\n",
            " '\\nTham khảo quy định về mức thu học phí năm học 2022-2023: https://hcmut.edu.vn/dao-tao/hoc-phi\\n \\tĐào tạo đại học, chương trình tiêu chuẩn: Từ khóa 2021: Học phí trọn gói theo học kỳ.\\nHọc phí học kỳ: 13.750.000 VNĐ/HK.\\nĐơn giá học phí tín chỉ vượt định mức: 805.000 VNĐ/TC.\\nĐơn giá học phí tín chỉ học lại GDTC: 805.000 VNĐ/TC.\\nĐào tạo đại học giảng dạy bằng tiếng Anh, định hướng Nhật Bản: Từ khóa 2021: Học phí trọn gói theo học kỳ.\\nChương trình\\t\\tHọc phí (VNĐ/HK)\\tĐơn giá học phí tín chỉ vượt định mức (VNĐ/HK)\\nCLC/TT/LKQT/CTQT\\t36.000.000\\t\\t\\t2.220.000\\nCLC-TCTN, TCTN\\t\\t27.500.000\\t\\t\\t980.000\\n'\n",
            " '\\nEm có thể đi dạy sau khi tốt nghiệp đại học, tùy vào tiêu chuẩn của cơ sở tuyển dụng.\\n'\n",
            " '\\nTrường có KTX tại quận 10 & KTX thuộc KTX ĐHQG-TpHCM, để được xem xét ở KTX em cần thỏa các điều kiện do KTX đưa ra.\\n'\n",
            " '\\nCơ hội việc làm cho ngành KHMT là rất lớn, …\\n'\n",
            " '\\nHằng năm, Khoa & Trường đều tổ chức ngày hội việc làm để em có cơ hội học hỏi, trao đổi và tham dự phỏng vấn với nhà tuyển dụng. Ngay từ năm 3, các em đã đi thực tập với các doanh nghiệp có liên hệ với Khoa/Trường, nếu năng lực của em phù hợp với yêu cầu của công ty em có thể có việc làm bán thời gian/toàn thời gian ngay từ thời điểm này.\\n'\n",
            " '\\nEm có thể du học tự túc hoặc bằng học bổng. Hằng năm, Trường đều phổ biến thông tin về cơ hội học bổng/ du học cho sinh viên thông qua website Khoa, Trường và nhiều kênh khác. \\n'\n",
            " '\\nEm hoàn toàn có thể theo học KHMT, vì trong quá trình học em sẽ được thầy/cô cung cấp kiến thức cũng như tư vấn về chương trình học.\\n'\n",
            " '\\nĐiều kiện để được cấp Giấy xác nhận hoãn nghĩa vụ quân sự là em có đăng ký môn học trong học kỳ, nghĩa là chừng nào em còn đang thực học tại Trường em sẽ được Trường hỗ trợ tối đa về việc này.\\n'\n",
            " '\\nTrường có chính sách hỗ trợ về việc giảm/ miễn giảm tiền học phí. Em có thể  liên hệ Phòng Công tác Chính trị- Sinh viên để được giúp đỡ. \\nNgoài ra, Trường còn có quỹ học bổng BKA, tiêu chí cho vay rất rộng mở, dễ tiếp cận: SV chỉ cần cam kết học tập ra Trường.\\n'\n",
            " '\\nBắt đầu từ năm 2019, sinh viên theo học chương trình đào tạo đại học chính quy  ngành KHMT & KTMT đều có thể đăng ký học liên thông đại học- cao học ngành Khoa học Máy tính ngay từ năm 3. Việc học liên thông này sẽ giúp em rút ngắn thời gian đào tạo thạc sĩ cũng như giảm chi phí đào tạo.\\n'\n",
            " '\\nEm có thể học ngành nào cũng được, miễn em yêu thích và đủ tiêu chuẩn theo học chương trình.\\n'\n",
            " '\\nTham khảo quy định về mức thu học phí năm học 2022-2023: https://hcmut.edu.vn/dao-tao/hoc-phi\\n'\n",
            " '\\nTại Khoa KH & KTMT, chỉ đào tạo chương trình tiêu chuẩn và chương trình giảng dạy bằng tiếng Anh, chương trình định hướng Nhật Bản, không đào tạo chương trình tiên tiến.\\n'\n",
            " '\\nNếu em học chương trình chính quy tiêu chuẩn thì em sẽ học ở CS2, Dĩ An, Bình Dương. Nếu em học chương trình trình giảng dạy bằng tiếng Anh, chương trình định hướng Nhật Bản thì em sẽ học ở CS1, Lý Thường Kiệt, Quận 10.\\n'\n",
            " '\\nEm nên học ngành KHMT.\\n'\n",
            " '\\n4 năm (+2 năm), bằng cử nhân, áp dụng từ 2019.\\n'\n",
            " '\\nEm không giỏi vậy lý vẫn có thể theo học ngành KHMT, vì ngành không chuyên sâu về các môn cơ bản, CTĐT tập trung cung cấp kiến thức ngành, giúp em hiểu và có thể vận dụng kiến thức ngành trong công việc thực tiễn.\\n'\n",
            " '\\nEm có thể học được ngành KTMT vì CTĐT tập trung cung cấp kiến thức ngành, giúp em hiểu và có thể vận dụng kiến thức ngành trong công việc thực tiễn.\\n'\n",
            " '\\nMỗi ngành đều có thuận lợi và khó khăn nhất định, quan trọng là sự yêu thích và chịu khó học hỏi, tìm tòi kiến thức từ ngành học.\\n'\n",
            " '\\nTheo Quyết định 2931/ ĐHBK ngày 10/9/2021, Quy định chung về học vụ và đào tạo, áp dụng từ học kỳ 211 thì:\\n25.3 Chuyển ngành\\nNgười học được xem xét chuyển sang học một ngành đào tạo khác khi có đù các điều kiện sau:\\na)Không đang là sinh viên trình độ năm thứ nhất hoặc năm cuối khóa đối với trình độ đại học, không thuộc diện bị xem xét buộc thôi học và còn dù thời gian học tập theo quy định;\\nb)Đạt diều kiện trúng tuyển của ngành đào tạo trong cùng khóa tuyển sinh;\\nc)Ngành chuyển đến có đủ các điều kiện bảo đảm chất lượng, chưa vượt quá năng lực đào tạo của khoá tuyển sinh;\\nd)Được sự dồng ý của các Trưởng Khoa quản lý ngành chuyển đi và ngành chuyển đến.\\n\\n25.4 Chuyển chương trình\\nTrường hợp chuyển từ chương trình Kỹ sư Việt-Pháp dến chương trình đại trà, người học sẽ chuyển về ngành ban đầu khi trúng tuyển vào trường trước khi trúng tuyển vào chương trình Kỹ sư Việt-Pháp, hoặc được xem xét như trường hợp chuyển ngành nếu trúng tuyển trực tiếp vào chương trình Kỹ sư Việt-Pháp.\\nTrường họp chuyền từ chương trình dại trà đến chương trình Kỹ sư Việt-Pháp, thực hiện theo dề án tuyển sinh của chương trình Kỹ sư Việt-Pháp hoặc theo quy định dành riêng cho chương trình này.\\nTrường hợp chuyển từ chương trình Chất lượng cao, Tiến tiến đến chương trình đại trà, áp dụng quy dịnh về chuyển ngành.\\nTrường hợp chuyển từ chương trình đại trà dến chương trinh Chất lượng cao, Tiến tiến, thực hiện theo đồ án tuyển sinh bổ sung vào chương trình Chất lượng cao, Tiên tiến (nếu có). Trong trường họp trúng tuyển bổ sung, chi các học phần tương ứng với các học phần tổ chức học bàng tiếng Việt cùa chương trình Chất lượng cao, Tiên tiến mới được xem xét chuyển dổi kết quả học tập.\\n'\n",
            " '\\nTheo Quyết định 2933/ ĐHBK ngày 10/9/2021, Quy định học vụ và đào tạo Đại học, áp dụng từ học kỳ 211 thì:\\nĐiều 12. Dào tạo song ngành 12.1 Quy định chung\\nTrong thời gian dào tạo ngành thứ nhất, sinh viên được đăng ký học và tích lũy các học phần của ngành thứ nhất và của ngành thứ hai.\\nNgoại trừ các chưcmg trình dào tạo song ngàrih tuyển sinh ngay từ đầu, sinh viên được dăng ký học ngành thứ hai sớm nhất khi dã được xốp trình độ năm thứ hai của ngành thứ nhất và muộn nhất là 02 năm trước thời điểm tốt nghiệp ngành thứ hai. Tại thời điểm đăng ký, sinh viên phải đáp ứng các điều kiện sau:\\na)\\tĐiểm trung bình tích lũy xép loại khá trở lên và đáp ứng ngưỡng bảo đảm chất lượng của ngành thứ hai trong năm tuyển sinh, hoặc diểm trung bình tích lũy xếp loại trung bình và dáp ứng điều kiện trúng tuyển của ngành thứ hai trong năm tuyển sinh;\\nb)\\tĐược sự đồng ý của Trường Khoa quản lý ngành thứ hai căn cứ trên các tiêu chí đánh giá về năng lực đào tạo của ngành thứ hai.\\n'\n",
            " '\\nChương trình đào tạo liên thông Đại học – Thạc sĩ được triển khai từ năm học 2019-2020 cho phép sinh viên có học lực khá giỏi rút ngắn thời gian học tập (lợi ít nhất 1 năm) so với tổng thời gian đào tạo trình độ đại học và trình độ thạc sĩ của ngành tương ứng. Sinh viên tham dự chương trình có thể đăng ký học và tích lũy các môn học trình độ thạc sĩ từ năm 3 trong quá trình học đại học. Các môn học tích lũy này được xét công nhận cho các môn ở trình độ Đại học (lên đến 15 tín chỉ).\\nĐiều kiện tham dự chương trình liên thông:\\n+ Số tín chỉ tích lũy tại thời điểm xét: > 60\\n+ Điểm trung bình tích lũy tại thời điểm xét: > 7.0\\n+ Đăng ký ngành thạc sĩ phù hợp với ngành đại học.\\nChi tiết chương trình: http://www.pgs.hcmut.edu.vn/vi/lien-thong-dh-ths/2020-07-31-07-54-16/ke-hoach-dang-ky\\n'\n",
            " '\\n- Khoa KH & KT Máy tính hiện có 2 chương trình dành cho người vừa đi làm vừa đi học, thời gian học được tổ chức ngoài giờ. Đối tượng tham gia xét tuyển: tốt nghiệp THPT.\\n- Chương trình Vừa làm Vừa học (VLVH) ngành Khoa học Máy tính với 10 học kỳ, chương trình Đào tạo Từ xa (ĐTTX) ngành Công nghệ Thông tin với 08 học kỳ. Trong cả 2 chương trình này, học viên sẽ được xét miễn giảm các môn đã học nếu được Hội đồng ngành đồng ý.\\n- Cả 2 chương trình đều hướng tới đào tạo người học thông qua hình thức đào tạo ngoài giờ, tối ưu thời gian của người học. Các giảng viên giảng dạy trong chương trình là các thầy/cô giàu kinh nghiệm và từ chương trình đào tạo chính quy qua dạy nên sẽ đảm bảo về mặt truyền đạt kiến thức, không chênh lệch so với các hệ đào tạo chính quy. Ngoài ra, việc tổ chức/kiểm tra/ thi của hệ này chỉ tổ chức ngoài giờ, cuối tuần, giúp người học có thể dễ dàng sắp xếp công việc để tham gia việc học.\\n'\n",
            " '\\nTheo từ điển Cambridge thì “kỹ thuật” (engineering) có nghĩa là sự nghiên cứu để ứng dụng các nguyên lý khoa học để thiết kế và xây dựng các máy móc, cấu trúc và các hệ thống khác nhau; “máy tính” (computer) là một máy điện tử sử dụng cho mục đích lưu trữ, tổ chức và tìm kiếm các từ ngữ, các con số và các hình ảnh để tính toán và điều khiển các máy khác. Như vậy, Kỹ thuật Máy tính theo địnhh nghĩa là ngành sẽ ứng dụng các nguyên lý khoa học để thiết kế và hiện thực các hệ thống máy tính khác nhau nhằm nhiều mục đích.\\nTại Khoa KH&KTMT, ngành Kỹ thuật Máy tính hướng đến mục tiêu đào tạo sinh viên một cách toàn diện để có thể thiết kế và hiện thực được các hệ thống tính toán hoàn chỉnh phục vụ cho các loại ứng dụng khác nhau từ các ứng dụng sử dụng trí tuệ nhân tạo cho đến các ứng dụng trên nền tảng IoT hay các ứng dụng liên quan đến chuỗi khối (blockchain). Cụ thể, sinh viên có thể phát triển được các hệ thống sau khi hoàn tất chương trình đào tạo KTMT:\\n- Hướng trí tuệ nhân tạo: nhận dạng đối tượng (gương mặt, biển số xe, làn đường,…); nhận dạng phân tích âm thanh (giọng nói, nhạc,…); phân tích các hành vi bất thường trên môi trường mạng tốc độ cao; điều khiển đèn giao thông bằng học tăng cường (reinforcement learning).\\n- Hướng hệ thống nhúng: các hệ thống điều khiển tự động như nhà thông minh, nông nghiệp thông minh (tưới tiêu tự động); hệ thống quản lý giao nhận hàng tự động (smart box); các hệ thống điều khiển tự động máy móc công nghiệp (máy CNC, máy sấy trái cây,…).\\n- Hướng Internet vạn vật (IoT): các hệ thống quan trắc môi trường, chất lượng nguồn nước; các hệ thống giám sát xe, giám sát kho bãi; các hệ thống phục vụ nông nghiệp công nghệ cao; các hệ thống và các ứng dụng dựa trên các thiết bị di động.\\n- Hướng tính toán hiệu năng cao – điện toán đám mây: các hệ thống xử lý song song, tính toán trên nền tảng đa nhân; các hệ thống phòng chống tấn công mạng tốc độ cao sử dụng các thiết bị phần cứng chuyên dụng; các hệ thống phân tích chuỗi dữ liệu sinh học; các hệ thống điện toán đám mây như Microsoft Azure, Google Cloud, Amazon Cloud,…\\n- Hướng mạng máy tính và an ninh mạng: các hệ thống dựa trên chuỗi khối; các hệ thống bảo mật mạng ở nhiều mức khác nhau; các hệ thống mật mã; các ứng dụng web và các hệ thống mạng.\\n'\n",
            " '\\nNhư đã trình bày ở trên, “Kỹ thuật Máy tính” nói chung là hướng đến thiết kế và hiện thực toàn bộ hệ thống máy tính sử dụng các nguyên lý khoa học. Một hệ thống máy tính hoàn chỉnh sẽ bao gồm 3 lớp cơ bản là: phần cứng (các board mạch từ đơn giản đến phức tạp như Arduino hay Raspberry; các nền tảng tính toán như GPU hay các bộ xử lý đa nhân); phần mềm hệ thống (hệ điều hành, các trình biên dịch, các dịch vụ điều khiển thiết bị); và phần mềm ứng dụng, trí tuệ nhân tạo (ví dụ TensorFlow, Apache Spark).\\n- Ngành KTMT ở trường Đại học Bách khoa – ĐHQG TPHCM giảng dạy sinh viên ở cả ba lớp nêu trên nhưng tập trung nhiều vào phần mềm hệ thống và phần cứng. Từ đó, sinh viên có thể lập trình được và phát triển được các ứng dụng không chỉ thực thi được trên máy tính cá nhân (máy tính để bàn hay máy tính xách tay) mà còn thực thi được trên các board mạch hệ thống nhúng và các hệ thống tính toán chuyên biệt như hệ thống đa nhân, GPU hay các chip phần cứng lập trình được. Trên cơ sở đó, sinh viên tốt nghiệp ngành KTMT sẽ có thể tham gia được vào các dự án thuộc các hướng như đã nêu ở Câu 1.\\n- Ngược lại: ngành KHMT ở trường Đại học Bách khoa – ĐHQG TPHCM tập trung nhiều vào phần mềm ứng dụng và một phần mức phần mềm hệ thống. Sinh viên ngành KHMT có thể làm các công việc sau sau khi tốt nghiệp: Thiết kế và xây dựng các phầm mềm máy tính cho các ngân hàng, các tổ chức tài chính, hành chính và thương mại,…; Thiết kế và xây dựng các ứng dụng cho các thiết bị di động, ứng dụng thương mại điện tử trên nền Web, các trò chơi trên máy tính và thiết bị di động,…; Quản trị và xây dựng các giải pháp đảm bảo an toàn cho các hệ thống máy tính và hệ thống mạng máy tính.\\n'\n",
            " '\\nNgành Kỹ thuật Máy tính ở trường Đại học Bách khoa – ĐHQG TPHCM đã được trình bày ở Câu 1 và Câu 2. Ngành Công nghệ thông tin ở các trường Đại học khác thường hướng đến việc giảng dạy sinh viên phát triển phần mềm bằng một ngôn ngữ cụ thể hoặc sử dụng những phần mềm sẵn có, hơn là hướng sinh viên đến toàn bộ hệ thống tính toán hoàn chỉnh.\\n'\n",
            " '\\nCó 3 chuyên ngành cụ thể ở ngành Kỹ thuật Máy tính ở trường Đại học Bách khoa – ĐHQG TPHCM:\\n- Chuyên ngành Internet vạn vật và An ninh mạng: nếu theo đuổi chuyên ngành này, sinh viên sẽ đào sâu các kiến thức và kỹ năng liên quan đến các hướng Internet vạn vật; hướng mạng máy tính và an ninh mạng (chi tiết các hướng này đã nêu ở Câu 1)\\n- Chuyên ngành Các hệ thống tính toán hiện đại: nếu theo đuổi chuyên ngành này, sinh viên sẽ đào sâu các kiến thức và kỹ năng liên quan đến các hướng trí tuệ nhân tạo, hướng hệ thống nhúng và hướng tính toán hiệu năng cao (chi tiết các hướng này đã nêu ở Câu 1)\\n- Chuyên ngành Kỹ thuật Máy tính (trùng tên với ngành): sinh viên không theo một trong hai chuyên ngành cụ thể nêu trên sẽ được công nhận thuộc chuyên ngành này. Khi đó, sinh viên có thể học một các tổng quan tất cả các hướng đã nêu.\\n'\n",
            " '\\nSinh viên không cần phải có kiến thức hay kỹ năng gì cụ thể, tất cả sẽ được hướng dẫn và giảng dạy từ đầu. Tuy nhiên, sinh viên cần có niềm đam mê và hứng thú với ngành hay cụ thể hơn là với các hướng học tập nghiên cứu đã nêu trên.\\n'\n",
            " '\\nHoàn toàn có thể, sinh viên có thể phát triển được các hệ thống dựa trên trí tuệ nhân tạo như: nhận dạng đối tượng (gương mặt, biển số xe, làn đường,…); nhận dạng phân tích âm thanh (giọng nói, nhạc,…); phân tích các hành vi bất thường trên môi trường mạng tốc độ cao; phát triển các hệ thống dựa trên AI cho các ngành khác (hệ điều khiển tín hiệu giao, phân tích hệ gen của virus, nhận dang bệnh cây trồng).\\n'\n",
            " '\\nHoàn toàn có thể, sinh viên khi tốt nghiệp ngành KTMT có khả năng phân tích đánh giá mức độ bảo mật của một hệ thống tính toán, một website; có khả năng thiết kế và hiện thực các hệ thống phòng chống tấn công mạng ở cả mức phần mềm (tốc độ thấp) và mức phần cứng bằng các thiết bị chuyên dụng (tốc độ cao). Ngoài ra, sinh viên còn được cung cấp những kiến thức hàn lâm cơ bản về mật mã học (mã khối, mã đối xứng, mã không đối xứng, chữ ký điện tử, blockchain).\\n'\n",
            " '\\nMột trong những hướng chủ đạo của ngành Kỹ thuật Máy tính là phát triển các hệ thống dựa trên nền tảng vạn vật kết nối. Đây là một trong những thế mạnh của thầy và trò ngành Kỹ thuật Máy tính ở trường Đại học Bách khoa – ĐHQG TPHCM.\\n'\n",
            " '\\nHoàn toàn có thể, sinh viên có thể phát triển được các hệ thống nhúng từ đơn giản đến phức tạp phục vụ cho nhiều mục đích khác nhau như giám sát, điều khiển thiết bị từ xa, điều khiển máy móc tự động.\\n'\n",
            " '\\nĐây cũng là một thế mạnh khác của thầy và trò ngành KTMT ở trường Đại học Bách khoa – ĐHQG TPHCM. Taị đây, thầy và trò của ngành KTMT đang có một trong những hệ thống tính toán hiệu năng cao nhất và hiện đại nhất Việt Nam. Bên cạnh đó, thầy trò ngành Kỹ thuật Máy tính cũng đang sở hữu những hệ thống tính toán chuyên dụng như GPU hay các chip phần cứng lập trình được có thể nói là hiện đại nhất ở khu vự phía nam.\\n'\n",
            " '\\nHoàn toàn có thể, hiện tại thầy trò ngành Kỹ thuật Máy tính ở trường Đại học Bách khoa – ĐHQG TPHCM có liên kết rất chặt chẽ với những công ty thiết kế vi mạch hàng đầu khu vực TPHCM nói riêng và miền nam nói chung như Renesas, Marvell, AMCC,… Chương trình đào tạo có hẳng một môn liên quan đến thiết kế vi mạch được thiết kế và giảng dạy trực tiếp bởi chuyên gia hàng đầu từ Renesas Việt Nam.\\n'\n",
            " '\\nNgoài 100% sinh viên tốt nghiệp có việc làm ở các công ty lớn hoặc đi du học, các sinh viên ngành KTMT trong 05 năm gần đây (2017-2022) còn có thành tích học thuật nghiên cứu khoa học rất xuất sắc. Cụ thể như sau:\\n- 03 bài báo khoa học tạp chí uy tín hàng đầu thế giới (ISI và Scopus) (Sinh viên là tác giả chính)\\n- 10 bài báo khoa học các hội nghị uy tín thế giới (Sinh viên là tác giả chính)\\n- Giải 03 cuộc đua số toàn quốc do FPT tổ chức\\n- Giải nhất cuộc thi lập trình Markethon với sản phẩm Máy check-in IoTs\\n- Các giải thưởng SV NCKH các cấp\\n'\n",
            " '\\nNếu cần tư vấn thêm các vấn đề liên quan đến ngành Kỹ thuật Máy tính xin mời xem trang tiếp theo\\n- Trang Facebook chính thức của ngành Kỹ thuật Máy tính trường Đại học Bách khoa – ĐHQG TPHCM: https://www.facebook.com/hcmut.ce/\\n- Website chính thức của khoa Khoa học và Kỹ thuật Máy tính – trường Đại học Bách khoa – ĐHQG TPHCM: https://cse.hcmut.edu.vn/dai-hoc-ky-thuat-may-tinh/\\n'\n",
            " '\\nChào bạn, bạn vui lòng gửi mail về địa chỉ mail admission@hcmut.edu.vn, cung cấp thông tin (như mã hồ sơ, họ tên, số CMND/CCCD) và trình bày tình trạng của bạn để được hỗ trợ bạn nhé.\\t\\n'\n",
            " '\\nChào bạn, điểm xét tuyển của phương thức 2 không có điểm thưởng của các thành tích khác bạn nhé. Điểm xét tuyển phương thức 2 là xét theo tổng các điểm trung bình các môn (thuộc tổ hợp môn xét tuyển) của các năm lớp 10, 11, 12; theo bài luận của thí sinh và thư giới thiệu của giáo viên.\\n'\n",
            " '\\nChào bạn, Trường Đại học Bách khoa có đào tạo ngành Kỹ thuật máy tính và Khoa học máy tính với 2 tổ hợp xét tuyển là A00 (Toán, Lý, Hóa) và A01 (Toán, Lý, Anh). Vậy nên khi thi tổ hợp môn Khoa học xã hội thì không đủ điều kiện để xét tuyển vào ngành này nhé bạn.\\n'\n",
            " '\\nChào bạn, bạn không cần gửi lại bộ hồ sơ khác nha bạn. Bạn vui lòng gửi mail về địa chỉ admission@hcmut.edu.vn và trình bày tình trạng kèm theo mã hồ sơ của bạn để được hỗ trợ bạn nhé.\\n'\n",
            " '\\nChào bạn, về vấn đề này bạn vui lòng gửi câu hỏi lên trang hỗ trợ trực tuyến của phòng đào tạo BKSI để được hỗ trợ bạn nhé\\n'\n",
            " '\\nChào bạn, về vấn đề này, bạn vui lòng gửi mail về địa chỉ admission@hcmut.edu.vn và trình bày tình trạng kèm theo mã hồ sơ của bạn để được hỗ trợ bạn nhé.\\n'\n",
            " '\\nChào bạn, trường chỉ làm việc trong giờ hành chính từ thứ 2 đến thứ 6 thôi bạn nhé.\\n'\n",
            " '\\nBạn vui lòng theo dõi tình trạng hồ sơ trên cổng của ĐHQG hoặc trên cổng mybk để biết được tình trạng hồ sơ của bạn nhé. Nếu bạn đã thấy hiện dòng chữ \"Hồ sơ đã được xác nhận\" hoặc mã \"QSB-UTXT-....\" là hồ sơ đã xác nhận rồi bạn nhé\\n'\n",
            " '\\nChào bạn, thời gian công bố kết quả theo phương thức 1.1 dự kiến sẽ có trước 17g ngày 05/07/2023 bạn nhé\\n'\n",
            " '\\nChào bạn, trường Đại học Bách khoa HCM chỉ có 1 ngành Kiến trúc xét theo tổ hợp C01 (Toán, Lý, Văn) thôi bạn nhé. Vì vậy, ngành Logistics và quản lý chuỗi cung ứng không xét theo khối C mà chỉ xét khối A00, A01.\\n'\n",
            " '\\nChào bạn, hiện tại vẫn chưa có thông tin về công thức tính điểm của năm nay bạn nhé. Theo như năm 2022 thì công thức tính điểm sẽ được công bố cùng lúc với điểm chuẩn xét tuyển của phương thức 5.\\n'\n",
            " '\\nChào bạn, KTX Bách khoa tọa lạc tại số 497 Hòa Hảo, quận 10 chỉ cách trường 6 phút đi xe thôi bạn nhé\\n'\n",
            " '\\nChào bạn, thời gian công bố kết quả theo phương thức 2 dự kiến sẽ có trước 17g ngày 26/06/2023 bạn nhé\\n'\n",
            " '\\nChào bạn, về vấn đề này, bạn vui lòng liên hệ đến PĐT Sau đại học qua số điện thoại 02838647256, sau đó bấm số nội bộ 5263 để được hỗ trợ bạn nhé\\n'\n",
            " '\\nChào bạn, bạn có thể tham khảo các mốc thời gian đăng ký xét tuyển cho phương thức 5 như sau: \\n1. Thí sinh đăng ký nguyện vọng tại cổng tuyển sinh của Bộ GD&ĐT: 10/07/2023 đến trước 17g00, 30/07/2023\\n2, Đăng ký bổ sung các thông tin xét tuyển tại cổng đăng ký tuyển sinh của trường ĐHBK: Trước ngày 30/07/2023\\nVề chi tiết các thông tin xét tuyển liên quan đến phương thức 5, bạn có thể tham khảo tại đây: https://hcmut.edu.vn/tuyen-sinh/dai-hoc-chinh-quy/phuong-thuc-tuyen-sinh/xet-tuyen-tieu-chi\"\\n'\n",
            " '\\nChào bạn, ngành khoa học máy tính thuộc chương trình giảng dạy bằng tiếng Anh có học phí 40 triệu/HK, mỗi năm sẽ có 2 học kỳ chính nhé bạn.\\n'\n",
            " '\\nChào bạn, nếu bạn không có điểm thi ĐGNL thì bạn vẫn có thể xét tuyển được cho phương thức 5 nhưng khi đó sẽ lấy điểm thi THPT QG quy đổi ra cột điểm ĐGNL cho bạn, còn việc quy đổi như thế nào thì vẫn chưa có thông tin ạ\\n'\n",
            " '\\nChào bạn, hiện tại vẫn chưa có thông tin về thời gian công bố kết quả xét tuyển phương thức 5 Xét tuyển kết hợp nhiều tiêu chí. Hiện tại, đang có 2 mốc thời gian như sau:\\n1. Thí sinh đăng ký nguyện vọng tại cổng tuyển sinh của Bộ GD&ĐT: 10/07/2023 đến trước 17g00, 30/07/2023\\n2, Đăng ký bổ sung các thông tin xét tuyển tại cổng đăng ký tuyển sinh của trường ĐHBK: Trước ngày 30/07/2023\\nVề chi tiết các thông tin xét tuyển liên quan đến phương thức 5, bạn có thể tham khảo tại đây: https://hcmut.edu.vn/tuyen-sinh/dai-hoc-chinh-quy/phuong-thuc-tuyen-sinh/xet-tuyen-tieu-chi\"\\n'\n",
            " '\\nChào bạn, về vấn đề mật khẩu của tài khoản mybk thì bạn gửi mail về admission@hcmut.edu.vn để được hỗ trợ bạn nhé\\n'\n",
            " '\\nNăm 2023 hiện đang để trọng số của các cột điểm trong phương thức 5 tương ứng là 90% điểm học lực gồm ĐGNL 50-75%, THPT QG 20-30%, Học bạ 0-5% và 5% thành tích cá nhân, 5% hoạt động xã hội, văn thể mỹ bạn nhé\\n'\n",
            " '\\nBộ hồ sơ Ưu tiên xét tuyển theo quy định của ĐHQG-HCM bao gồm:\\n\\nPhiếu đăng ký UTXT theo mẫu (được in từ hệ thống đăng ký xét tuyển UTXT ĐHQG-HCM) sau khi hoàn thành Bước 1 và Bước 2 (có đóng dấu xác nhận của trường THPT)\\nMột bài luận được thí sinh viết tay trên giấy A4, trình bày động cơ học tập và sự phù hợp của năng lực bản thân với ngành học, trường học (độ dài tối đa là 1 mặt giấy A4)\\nMột thư giới thiệu của giáo viên trường THPT, nơi thí sinh học lớp 12 (không cần đóng dấu của trường THPT)\\nBản sao học bạ 3 năm trung học phổ thông (có đóng dấu xác nhận của trường THPT)\\nBản sao chứng chỉ ngoại ngữ quốc tế (nếu có)\\nBản sao các giấy tờ minh chứng thành tích (nếu có)\\n'\n",
            " '\\n- Khoa KH & KT Máy tính hiện có 2 chương trình dành cho người vừa đi làm vừa đi học, thời gian học được tổ chức ngoài giờ. Đối tượng tham gia xét tuyển: tốt nghiệp THPT.\\n- Chương trình Vừa làm Vừa học (VLVH) ngành Khoa học Máy tính với 10 học kỳ, chương trình Đào tạo Từ xa (ĐTTX) ngành Công nghệ Thông tin với 08 học kỳ. Trong cả 2 chương trình này, học viên sẽ được xét miễn giảm các môn đã học nếu được Hội đồng ngành đồng ý.\\n- Cả 2 chương trình đều hướng tới đào tạo người học thông qua hình thức đào tạo ngoài giờ, tối ưu thời gian của người học. Các giảng viên giảng dạy trong chương trình là các thầy/cô giàu kinh nghiệm và từ chương trình đào tạo chính quy qua dạy nên sẽ đảm bảo về mặt truyền đạt kiến thức, không chênh lệch so với các hệ đào tạo chính quy. Ngoài ra, việc tổ chức/kiểm tra/ thi của hệ này chỉ tổ chức ngoài giờ, cuối tuần, giúp người học có thể dễ dàng sắp xếp công việc để tham gia việc học.\\n'], 62\n",
            "I: [ 4  4  5  6  7  8  9  8  8 10 11 12  7 13  6  7 14 15  6 14 11 11  4  5\n",
            " 14 14 14 14  4  4 14 11 14 14 14 14 14 14 16 17  3  1 20  3 18  3 17  3\n",
            " 19 20  1  9 19  2  2  7  1 19 21  1  3  1], 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text.lower() to change string to lowercase"
      ],
      "metadata": {
        "id": "bw3b-NcbQ71z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def tokenize(string):\n",
        "#     return string.split(' ')"
      ],
      "metadata": {
        "id": "AmxMbHEyRuUm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_word(set_corpus):\n",
        "    return (lambda prv, cur: set(prv).union(set(cur)), set_corpus, [])"
      ],
      "metadata": {
        "id": "Cf_G9bEoRwAY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, Y_train = read_csv('train.csv')\n",
        "# # print(X_train.shape)\n",
        "# X_test, Y_test = read_csv('test.csv')\n",
        "# # nltk.download('stopwords')\n",
        "# # stop_words = set(stopwords.words('english'))\n",
        "# # maxLen = len(max(X_train, key=len).split())\n",
        "# # index = 1\n",
        "# # for i in range(len(X_train)):\n",
        "# #   #  X_train[i] = X_train[i].lower()\n",
        "# #   # print(X_train[i])\n",
        "# #   word_tokens = tokenize(X_train[i].lower())\n",
        "# #   no_sw = [w for w in word_tokens if not w in stop_words]\n",
        "# #   stem = [ps.stem(w) for w in no_sw]\n",
        "# #   filtered_sentence = (\" \").join(stem)\n",
        "# #   X_train[i] = filtered_sentence\n",
        "# #   # print(filtered_sentence)\n",
        "\n",
        "# # for i in range(len(X_test)):\n",
        "# #   #  X_test[i] = X_test[i].lower()\n",
        "# #   # print(X_test[i])\n",
        "# #   word_tokens = tokenize(X_test[i].lower())\n",
        "# #   no_sw = [w for w in word_tokens if not w in stop_words]\n",
        "# #   stem = [ps.stem(w) for w in no_sw]\n",
        "# #   filtered_sentence = (\" \").join(stem)\n",
        "# #   X_test[i] = filtered_sentence\n",
        "# #   # print(filtered_sentence)\n",
        "\n",
        "# # print(X_train[index], '/', Y_train[index])\n",
        "# # print(X_test[index], '/', Y_test[index])\n",
        "# # # print(maxLen)\n",
        "# a_train, b_train, c_train = stat(Y_train)\n",
        "# a_test, b_test, c_test = stat(Y_test)\n",
        "\n",
        "# print(f'train: {a_train} 0 label, {b_train} 1 label, {c_train} 2 label')\n",
        "# print(f'test: {a_test} 0 label, {b_test} 1 label, {c_test} 2 label')\n",
        "# print(X_train)\n",
        "\n",
        "# for i in range(len(I)):\n",
        "#   print(type(Q[i]))\n",
        "#   print(type(A[i]))\n",
        "#   print()\n",
        "\n",
        "# for i in range(len(I)):\n",
        "#   if type(Q[i]) is not str:\n",
        "#     Q[i] = \"\"\n",
        "#     Q_I[i] = -1\n",
        "#   else:\n",
        "#     Q[i] = text_normalize(Q[i])\n",
        "#     Q[i] = Q[i].lower()\n",
        "#     Q[i] = word_tokenize(Q[i], format='text')\n",
        "#     Q_I[i] = I[i]\n",
        "#     for w in stop_words:\n",
        "#       Q[i].replace(w, \"\")\n",
        "\n",
        "#   if type(A[i]) is not str:\n",
        "#     A[i] = \"\"\n",
        "#     A_I[i] = -1\n",
        "#   else:\n",
        "#     A[i] = text_normalize(A[i])\n",
        "#     A[i] = A[i].lower()\n",
        "#     A[i] = word_tokenize(A[i], format='text')\n",
        "#     A_I[i] = I[i]\n",
        "#     for w in stop_words:\n",
        "#       A[i].replace(w, \"\")\n",
        "\n",
        "# Q = [q for q in Q if q != \"\"]\n",
        "# A = [a for a in A if a != \"\"]\n",
        "# Q_I = [i for i in Q_I if i != -1]\n",
        "# A_I = [i for i in A_I if i != -1]\n",
        "\n",
        "eda_aug = EasyDataAugmenter()\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "# q = []\n",
        "# a = []\n",
        "# intent = []\n",
        "\n",
        "x = []\n",
        "\n",
        "for i in range(len(I)):\n",
        "  if type(Q[i]) is str:\n",
        "    norm = text_normalize(Q[i])\n",
        "    low = norm.lower()\n",
        "    text = word_tokenize(low, format='text')\n",
        "\n",
        "    aug = (eda_aug.augment(text))\n",
        "\n",
        "    x = [text] + aug\n",
        "\n",
        "    for j in range(len(x)):\n",
        "      for w in stop_words:\n",
        "        x[j].replace(w, \"\")\n",
        "      X.append(x[j])\n",
        "      Y.append(I[i])\n",
        "\n",
        "  #     q.append(x[j])\n",
        "  # else:\n",
        "  #   q.append(\"\")\n",
        "\n",
        "  # if type(A[i]) is str:\n",
        "  #   norm = text_normalize(A[i])\n",
        "  #   low = norm.lower()\n",
        "  #   text = word_tokenize(low, format='text')\n",
        "\n",
        "  #   aug = (eda_aug.augment(text))\n",
        "\n",
        "  #   x = [text] + aug\n",
        "  #   for j in range(len(x)):\n",
        "  #     for w in stop_words:\n",
        "  #       x[j].replace(w, \"\")\n",
        "  #     X_train.append(x[j])\n",
        "  #     Y_train.append(I[i])\n",
        "\n",
        "  #     a.append(x[j])\n",
        "  #     intent.append(I[i])\n",
        "  # else:\n",
        "  #   a.append(\"\")\n",
        "  #   intent.append(I[i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "s = 'đây là Hà Nội, thủ đô của Việt Nam'\n",
        "ts = word_tokenize(s, format='text')\n",
        "print(ts)\n",
        "\n",
        "# print(f'Q {type(Q)}')\n",
        "# print(f'A {(A)}')\n",
        "# print(f'I {len(I)}')\n"
      ],
      "metadata": {
        "id": "z8mhCk17RxpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66b5651-55f4-4510-fd80-99baa7051401"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "đây là Hà_Nội , thủ_đô của Việt_Nam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_QAI.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Q\", \"A\", \"I\"])\n",
        "\n",
        "    for i in range(len(Y)):\n",
        "        writer.writerow([X[i], \"\", Y[i]])\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "id": "Xc2E3EpGS3t0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('new_QAI.csv')\n",
        "rp = np.zeros(22)\n",
        "t_idx = []\n",
        "tr_idx = []\n",
        "idx = []\n",
        "\n",
        "for i in range(21):\n",
        "  idx.append([])\n",
        "\n",
        "for i in range(len(Y)):\n",
        "  rp[Y[i]-1] += 1\n",
        "  idx[Y[i]-1].append(i)\n",
        "\n",
        "print(idx)\n",
        "\n",
        "for i in range(len(rp)):\n",
        "  print(f\"{i+1}: {rp[i]}\")\n",
        "\n",
        "print(sum(rp))\n",
        "\n",
        "for l in idx:\n",
        "  tr_idx += l\n",
        "  t_idx += random.choices(l, k=(int(len(l)*0.2)))\n",
        "print(t_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXZ7G7bpHK7i",
        "outputId": "d7454ae1-bb24-44f6-b6ea-6aa0acbccfee"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[187, 188, 189, 190, 191, 231, 232, 233, 234, 235, 261, 262, 263, 264, 265, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285], [246, 247, 248, 249, 250, 251, 252, 253, 254, 255], [182, 183, 184, 185, 186, 197, 198, 199, 200, 201, 207, 208, 209, 210, 211, 217, 218, 219, 220], [0, 1, 2, 3, 4, 5, 6, 7, 105, 106, 107, 108, 133, 134, 135, 136, 137, 138, 139, 140], [8, 9, 10, 11, 12, 109, 110, 111, 112, 113], [13, 14, 15, 16, 17, 67, 68, 69, 70, 71, 86, 87, 88, 89, 90], [18, 19, 20, 21, 57, 58, 59, 60, 61, 72, 73, 74, 75, 256, 257, 258, 259, 260], [22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], [27, 28, 29, 30, 31, 236, 237, 238, 239, 240], [42, 43, 44, 45, 46], [47, 48, 49, 50, 51, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 145, 146, 147, 148], [52, 53, 54, 55, 56], [62, 63, 64, 65, 66], [76, 77, 78, 79, 80, 91, 92, 93, 94, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 141, 142, 143, 144, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173], [81, 82, 83, 84, 85], [174, 175, 176, 177], [178, 179, 180, 181, 212, 213, 214, 215, 216], [202, 203, 204, 205, 206], [221, 222, 223, 224, 225, 241, 242, 243, 244, 245, 266, 267, 268, 269, 270], [192, 193, 194, 195, 196, 226, 227, 228, 229, 230], [271, 272, 273, 274, 275]]\n",
            "1: 25.0\n",
            "2: 10.0\n",
            "3: 19.0\n",
            "4: 20.0\n",
            "5: 10.0\n",
            "6: 15.0\n",
            "7: 18.0\n",
            "8: 15.0\n",
            "9: 10.0\n",
            "10: 5.0\n",
            "11: 19.0\n",
            "12: 5.0\n",
            "13: 5.0\n",
            "14: 57.0\n",
            "15: 5.0\n",
            "16: 4.0\n",
            "17: 9.0\n",
            "18: 5.0\n",
            "19: 15.0\n",
            "20: 10.0\n",
            "21: 5.0\n",
            "22: 0.0\n",
            "286.0\n",
            "[285, 234, 263, 234, 191, 254, 248, 220, 200, 220, 136, 108, 139, 107, 12, 12, 17, 13, 15, 72, 19, 256, 34, 38, 40, 240, 28, 45, 49, 47, 99, 56, 62, 157, 144, 119, 126, 164, 93, 157, 170, 130, 94, 79, 83, 212, 202, 225, 221, 224, 192, 226, 273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = [x for x in tr_idx if x not in t_idx]\n",
        "test = [x for x in t_idx]\n",
        "print(train)\n",
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MeLn8-E8QNK",
        "outputId": "7496dd55-40b6-4133-c48a-fa7634e35eec"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[187, 188, 189, 190, 231, 232, 233, 235, 261, 262, 264, 265, 276, 277, 278, 279, 280, 281, 282, 283, 284, 246, 247, 249, 250, 251, 252, 253, 255, 182, 183, 184, 185, 186, 197, 198, 199, 201, 207, 208, 209, 210, 211, 217, 218, 219, 0, 1, 2, 3, 4, 5, 6, 7, 105, 106, 133, 134, 135, 137, 138, 140, 8, 9, 10, 11, 109, 110, 111, 112, 113, 14, 16, 67, 68, 69, 70, 71, 86, 87, 88, 89, 90, 18, 20, 21, 57, 58, 59, 60, 61, 73, 74, 75, 257, 258, 259, 260, 22, 23, 24, 25, 26, 32, 33, 35, 36, 37, 39, 41, 27, 29, 30, 31, 236, 237, 238, 239, 42, 43, 44, 46, 48, 50, 51, 95, 96, 97, 98, 100, 101, 102, 103, 104, 145, 146, 147, 148, 52, 53, 54, 55, 63, 64, 65, 66, 76, 77, 78, 80, 91, 92, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 127, 128, 129, 131, 132, 141, 142, 143, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 171, 172, 173, 81, 82, 84, 85, 174, 175, 176, 177, 178, 179, 180, 181, 213, 214, 215, 216, 203, 204, 205, 206, 222, 223, 241, 242, 243, 244, 245, 266, 267, 268, 269, 270, 193, 194, 195, 196, 227, 228, 229, 230, 271, 272, 274, 275]\n",
            "[285, 234, 263, 234, 191, 254, 248, 220, 200, 220, 136, 108, 139, 107, 12, 12, 17, 13, 15, 72, 19, 256, 34, 38, 40, 240, 28, 45, 49, 47, 99, 56, 62, 157, 144, 119, 126, 164, 93, 157, 170, 130, 94, 79, 83, 212, 202, 225, 221, 224, 192, 226, 273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "for i in train:\n",
        "  X_train.append(X[i])\n",
        "  Y_train.append(Y[i])\n",
        "\n",
        "X_test = []\n",
        "Y_test = []\n",
        "for i in test:\n",
        "  X_test.append(X[i])\n",
        "  Y_test.append(Y[i])"
      ],
      "metadata": {
        "id": "NTO1vzRw-UPQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.asarray(X_train)\n",
        "Y_train = np.asarray(Y_train)\n",
        "\n",
        "X_test = np.asarray(X_test)\n",
        "Y_test = np.asarray(Y_test)\n",
        "\n",
        "print(f'X_train: {X_train}')\n",
        "# print(f'Y_train: {Y_train}')\n",
        "print(len(Y_train))"
      ],
      "metadata": {
        "id": "sEl761SVosyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a920c07-ae7d-4fb6-9f6f-f5eea6148300"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: ['điểm xét tuyển theo phương_thức 2 ưu_tiên xét tuyển có được cộng thêm điểm thưởng khi có các thành_tích khác không ạ ?'\n",
            " 'điểm xét tuyển theo phương_thức ưu_tiên xét tuyển có được cộng thêm điểm thưởng khi có các thành_tích không ạ ?'\n",
            " 'điểm xét tuyển theo phương_thức 2 ưu_tiên không tuyển có được cộng thêm điểm thưởng khi có các thành_tích khác xét ạ ?'\n",
            " 'điểm xét tuyển theo phương_thức deuce ưu_tiên xét tuyển có được cộng thêm điểm thưởng chi có các thành_tích khác không ạ ?'\n",
            " 'cho em hỏi công_thức tính điểm phương_thức 5 xét tuyển kết_hợp nhiều tiêu_chí ạ ?'\n",
            " 'cho em hỏi công_thức tính điểm phương_thức 5 xét tuyển kết_hợp nhiều tiêu_chí ạ ?'\n",
            " 'cho em hỏi công_thức tính điểm phương_thức cinque xét tuyển kết_hợp nhiều tiêu_chí ạ ?'\n",
            " 'cho em công_thức tính điểm phương_thức 5 xét tuyển kết_hợp nhiều tiêu_chí ạ ?'\n",
            " 'cho em hỏi là pt5 xét tuyển thì không có đgnl có đủ điều_kiện xét không ạ'\n",
            " 'cho em hỏi là pt5 xét tuyển thì không có đgnl có đủ điều_kiện xét không ạ'\n",
            " 'cho em hỏi là đgnl xét tuyển thì không có pt5 có đủ điều_kiện xét không ạ'\n",
            " 'cho em hỏi pt5 xét tuyển thì không có đgnl có đủ điều_kiện xét không ạ'\n",
            " 'dạ cho em hỏi trọng_số các tiêu_chí_điểm trong phương_thức 5 là bao_nhiêu ạ ?'\n",
            " 'dạ cho em hỏi trọng_số các tiêu_chí_điểm trong phương_thức 5 là bao_nhiêu ạ ?'\n",
            " 'dạ cho em hỏi trọng_số các tiêu_chí_điểm trong 5 là bao_nhiêu ạ ?'\n",
            " 'dạ cho em 5 trọng_số các tiêu_chí_điểm trong phương_thức hỏi là bao_nhiêu ạ ?'\n",
            " 'dạ cho em hỏi trọng_số các tiêu_chí_điểm trong phương_thức fin là bao_nhiêu ạ ?'\n",
            " 'khoa kh & kt máy_tính có chương_trình dành cho người vừa đi làm vừa đi học hay không ? thí_sinh cần tham_gia thi_tuyển hay chỉ cần xét tuyển ?'\n",
            " 'khoa kh & karat máy_tính có chương_trình dành cho người vừa đi làm vừa đi học hay không ? thí_sinh cần tham_gia thi_tuyển hay chỉ cần xét tuyển ?'\n",
            " 'khoa kh & kt máy_tính có chương_trình dành cho người vừa đi làm vừa đi học hay không ? thí_sinh cần tham_gia thi_tuyển hay chỉ cần xét tuyển ?'\n",
            " 'khoa kh & kt máy_tính có chương_trình dành cho vừa đi làm vừa đi học hay không ? thí_sinh cần tham_gia thi_tuyển chỉ cần xét tuyển ?'\n",
            " 'cho em hỏi còn đợt nộp hồ_sơ cho chương_trình đào_tạo thạc_sĩ phương_thức tuyển thẳng nào không . do em chưa chuẩn_bị đủ hồ_sơ nên đợt nộp ngày 16/6/2023 em không_thể nộp kịp . em mong được phản_hồi . xin cám_ơn admin'\n",
            " 'em hỏi còn đợt nộp hồ_sơ cho chương_trình đào_tạo thạc_sĩ tuyển thẳng không . do em chưa chuẩn_bị đủ hồ_sơ nên đợt nộp ngày 16/6/2023 em không_thể nộp . em mong được phản_hồi . xin cám_ơn admin'\n",
            " 'cho pica hỏi còn đợt nộp hồ_sơ cho chương_trình đào_tạo thạc_sĩ phương_thức tuyển thẳng nào không . do em chưa chuẩn_bị đủ hồ_sơ nên đợt nộp ngày sixteen/sextet/2023 em không_thể nộp kịp . pica mong được phản_hồi . xin cám_ơn admin'\n",
            " 'cho em hỏi còn đợt nộp hồ_sơ cho chương_trình đào_tạo thạc_sĩ phương_thức tuyển thẳng nào không . do em chưa chuẩn_bị đủ hồ_sơ nên đợt nộp ngày 16/6/2023 em không_thể nộp kịp . em mong được phản_hồi . xin cám_ơn admin'\n",
            " 'cho em hỏi trường xét phương_thức kết_hợp 5 là vào ngày mấy ạ'\n",
            " 'cho em hỏi trường xét phương_thức kết_hợp 5 là vào ngày mấy ạ'\n",
            " 'cho em hỏi trường xét phương_thức kết_hợp 5 là vào mấy ạ'\n",
            " 'cho em trường hỏi xét phương_thức kết_hợp 5 là vào ngày mấy ạ'\n",
            " 'hồ_sơ xét tuyển theo phương_thức 2 bị sai nơi sinh thì phải làm_sao ?'\n",
            " 'hồ_sơ xét tuyển theo phương_thức sai bị 2 nơi sinh thì phải làm_sao ?'\n",
            " 'xét tuyển theo phương_thức 2 bị sai nơi sinh thì phải làm_sao ?'\n",
            " 'hồ_sơ xét tuyển theo phương_thức 2 bị sai nơi sinh thì phải làm_sao ?'\n",
            " 'hồ_sơ xét tuyển theo phương_thức deuce bị sai nơi sinh thì phải làm_sao ?'\n",
            " 'hồ_sơ xét tuyển theo phương_thức 2 của em bị sai thông_tin khu_vực ưu_tiên thì có cần nộp lại bộ hồ_sơ khác không ạ ?'\n",
            " 'hồ_sơ xét tuyển theo phương_thức 2 của em thông_tin sai bị khu_vực ưu_tiên thì có cần nộp lại bộ hồ_sơ khác không ạ ?'\n",
            " 'hồ_sơ xét tuyển theo phương_thức 2 của em bị sai thông_tin khu_vực ưu_tiên thì có cần nộp lại bộ hồ_sơ khác không ạ ?'\n",
            " 'hồ_sơ xét theo phương_thức 2 của em bị sai thông_tin khu_vực ưu_tiên có cần nộp lại bộ hồ_sơ khác không ạ ?'\n",
            " 'trong quá_trình nhập thông_tin em có ghi sai thông_tin môn tiếng anh lớp 10 từ 8.0 thành 8.4 mong trường xem_xét và sửa lại giúp em . em cảm_ơn'\n",
            " 'quá_trình nhập thông_tin em có ghi sai môn tiếng anh lớp 10 từ 8.0 thành.4 mong trường xem_xét và sửa lại giúp em . em cảm_ơn'\n",
            " 'trong quá_trình nhập thông_tin em có ghi sai thông_tin môn tiếng anh lớp 10 từ VIII.0 thành eight.quartet mong trường xem_xét và sửa lại giúp em . em cảm_ơn'\n",
            " 'trong quá_trình nhập tiếng em có ghi sai thông_tin môn thông_tin anh lớp 10 từ 8.0 thành 8.4 mong trường xem_xét và sửa em giúp em . lại cảm_ơn'\n",
            " 'trong quá_trình nhập thông_tin em có ghi sai thông_tin môn tiếng anh lớp 10 từ 8.0 thành 8.4 mong trường xem_xét và sửa lại giúp em . em cảm_ơn'\n",
            " 'làm_sao để biết hồ_sơ gửi đi đã hợp_lệ hay chưa ạ ?'\n",
            " 'làm_sao để biết hồ_sơ gửi đi hợp_lệ hay chưa ạ ?'\n",
            " 'làm_sao để biết hồ_sơ gửi đi đã hợp_lệ hay chưa ạ ?'\n",
            " 'các trường đại_học khác có ngành công_nghệ_thông_tin ( cntt ) , trường đhbk chỉ có hai ngành : khoa_học máy_tính ( khmt ) và ngành kỹ_thuật máy_tính ( ktmt ) ._vậy hai ngành này có giống với ngành cntt của các trường đh khác không ?'\n",
            " 'các trường đại_học khác có ngành ( cntt ) , trường chỉ có hai ngành : khoa_học máy_tính ( ) và ngành kỹ_thuật máy_tính ( ktmt ) ._vậy hai ngành này có giống với ngành cntt của các trường đh khác không ?'\n",
            " 'các trường đại_học khác có ngành công_nghệ_thông_tin ( cntt ) , trường đhbk chỉ có hai ngành : khoa_học máy_tính ( khmt ) và ngành kỹ_thuật máy_tính ( ktmt ) ._vậy hai ngành này có giống với ngành cntt của các trường đh khác không ?'\n",
            " 'các trường đại_học khác có ngành trường ( cntt ) , trường có chỉ có hai ngành : khoa_học máy_tính ( khmt ) và ngành kỹ_thuật máy_tính ( ktmt ) ._vậy hai ngành này đhbk giống với ngành cntt của các công_nghệ_thông_tin đh khác không ?'\n",
            " 'khác nhau giữa ngành khmt và ktmt ?' 'khác nhau giữa ngành khmt và ?'\n",
            " 'khác giữa nhau ngành khmt và ktmt ?'\n",
            " 'khác nhau giữa ngành khmt và ktmt ?'\n",
            " 'ngành khmt và ktmt , ngành học nào_dễ hơn .'\n",
            " 'ngành khmt và ktmt , ngành học nào_dễ hơn .'\n",
            " 'sự khác_biệt giữa ngành kỹ_thuật máy_tính và ngành khoa_học máy_tính ở trường đại_học bách_khoa –_đhqg tphcm là gì ?'\n",
            " 'sự khác_biệt giữa ngành kỹ_thuật máy_tính và ngành khoa_học máy_tính ở trường đại_học bách_khoa –_đhqg tphcm là gì ?'\n",
            " 'sự khác_biệt giữa ngành kỹ_thuật máy_tính và ngành khoa_học máy_tính ở tphcm đại_học bách_khoa –_đhqg trường là gì ?'\n",
            " 'sự khác_biệt giữa kỹ_thuật máy_tính và công_nghệ_thông_tin là gì ?'\n",
            " 'sự khác_biệt giữa kỹ_thuật máy_tính và công_nghệ_thông_tin là gì ?'\n",
            " 'gì khác_biệt giữa kỹ_thuật máy_tính và công_nghệ_thông_tin là sự ?'\n",
            " 'nếu ban_đầu em học ngành khmt , sau đó , em thấy không phù_hợp , em có_thể chuyển sang ngành ktmt được không ?'\n",
            " 'nếu ban_đầu em học ngành khmt , sau đó , em thấy không phù_hợp , em có_thể chuyển sang ngành ktmt được không ?'\n",
            " 'nếu ban_đầu em học ngành khmt , sau đó , pica thấy không phù_hợp , em có_thể chuyển tattle ngành ktmt được không ?'\n",
            " 'nếu ban_đầu em học ngành khmt , đó , em thấy phù_hợp , em có_thể chuyển sang ngành ktmt được không ?'\n",
            " 'sau khi học 1 thời_gian , em muốn chuyển_ngành khác hoặc chuyển hình_thức đào_tạo thì có được phép không ? vd từ ngành khmt sang ngành ktmt , vd từ chương_trình chất_lượng cao_sang chương_trình chính_quy đại_trà ?'\n",
            " 'sau được học 1 thời_gian , em muốn chuyển_ngành khác hoặc chuyển hình_thức đào_tạo thì có khi phép không ? vd từ ngành khmt sang ngành ktmt , vd từ chương_trình cao_sang chất_lượng chương_trình chính_quy đại_trà ?'\n",
            " 'sau khi học 1 thời_gian , em muốn chuyển_ngành khác hoặc chuyển hình_thức đào_tạo thì có được phép không ? vd từ ngành sang ngành ktmt , vd từ chương_trình cao_sang chương_trình chính_quy ?'\n",
            " 'sau chi học unity thời_gian , em muốn chuyển_ngành khác hoặc chuyển hình_thức đào_tạo thì có được phép không ? vd từ ngành khmt sang ngành ktmt , VD từ chương_trình chất_lượng cao_sang chương_trình chính_quy đại_trà ?'\n",
            " 'sau khi học 1 thời_gian , em muốn chuyển_ngành khác hoặc chuyển hình_thức đào_tạo thì có được phép không ? vd từ ngành khmt sang ngành ktmt , vd từ chương_trình chất_lượng cao_sang chương_trình chính_quy đại_trà ?'\n",
            " 'em muốn học làm automaton , điều_khiển từ xa các thiết_bị trong gia_đình thì em nên học ngành nào ?'\n",
            " 'muốn học làm robot , điều_khiển từ xa các thiết_bị trong gia_đình thì em nên học ngành nào ?'\n",
            " 'em học không giỏi lắm , em nên học ngành nào ? ( khmt , ktmt )'\n",
            " 'em học không giỏi lắm , em nên học ngành nào ? ( khmt , ktmt )'\n",
            " 'em học không giỏi lắm , pica nên học ngành nào ? ( khmt , ktmt )'\n",
            " 'em học không lắm , em nên học ngành nào ? ( khmt , ktmt )'\n",
            " 'em học không giỏi lắm , học nên em ngành nào ? ( khmt , ktmt )'\n",
            " 'em thích làm web , em nên học ngành nào ?'\n",
            " 'em thích làm web , em nên học ngành pica nào ?'\n",
            " 'em thích làm network , em nên học ngành nào ?'\n",
            " 'em thích làm web , em nên ngành nào ?'\n",
            " 'em thích nên web , em làm học ngành nào ?'\n",
            " 'học_phí của ngành khmt , ktmt ?' 'ngành của học_phí khmt , ktmt ?'\n",
            " 'học_phí của ngành khmt , ktmt ?'\n",
            " 'trường có cho em vay tiền đóng tiền học_phí không ?'\n",
            " 'trường có cho em vay tiền đóng tiền học_phí không ?'\n",
            " 'trường có cho pica vay tiền đóng tiền học_phí không ?'\n",
            " 'trường có cho vay tiền đóng tiền học_phí không ?'\n",
            " 'trường cho có em vay tiền đóng tiền học_phí không ?'\n",
            " 'học_phí có không đắt ?' 'học_phí có đắt không ?' 'học_phí có không ?'\n",
            " 'cho em hỏi học_phí ngành khoa_học máy_tính chương_trình giảng_dạy bằng tiếng anh của trường được không ạ ?'\n",
            " 'cho em hỏi học_phí ngành khoa_học máy_tính chương_trình giảng_dạy bằng tiếng anh của được không ạ ?'\n",
            " 'cho pica hỏi học_phí ngành khoa_học máy_tính chương_trình giảng_dạy bằng tiếng anh của trường được không ạ ?'\n",
            " 'cho em hỏi học_phí ngành khoa_học máy_tính chương_trình ạ bằng tiếng anh của trường được không giảng_dạy ?'\n",
            " 'khi học xong ngành khmt , ktmt , em có được đi dạy không ?'\n",
            " 'khi học ngành xong khmt , ktmt , em có được đi dạy không ?'\n",
            " 'khi học xong ngành khmt , ktmt , pica có được đi dạy không ?'\n",
            " 'khi học xong ngành khmt , ktmt , em có được dạy không ?'\n",
            " 'khi học xong ngành khmt , ktmt , em có được đi dạy không ?'\n",
            " 'em học ngành khmt ra trường có việc_làm không ?'\n",
            " 'việc_làm học ngành khmt ra trường có em không ?'\n",
            " 'em học ngành khmt ra trường có việc_làm ?'\n",
            " 'em học ngành khmt ra trường có việc_làm không ?'\n",
            " 'trường có giới_thiệu việc_làm cho em không ?'\n",
            " 'trường cho giới_thiệu việc_làm có em không ?'\n",
            " 'trường có giới_thiệu việc_làm cho em không ?'\n",
            " 'trường có ký_túc_xá không ? em có được ở ktx không ?'\n",
            " 'trường không ký_túc_xá có ? em có được ở ktx không ?'\n",
            " 'trường có ký_túc_xá không ? em có được ở ktx không ?'\n",
            " 'trường có ký_túc_xá không ? pica có được ở ktx không ?'\n",
            " 'ktx bách_khoa ở quận 10 có gần trường không ạ ?'\n",
            " 'ktx bách_khoa ở quận 10 có gần trường không ạ ?'\n",
            " 'ktx bách_khoa ở quận x có gần trường không ạ ?'\n",
            " 'ktx bách_khoa ở 10 có gần trường không ạ ?'\n",
            " 'em học ngành ktmt hoặc khmt , em có_thể đi du_học được không ?'\n",
            " 'em học ngành ktmt hoặc khmt , em có_thể đi du_học được không ?'\n",
            " 'pica học ngành ktmt hoặc khmt , em có_thể đi du_học được không ?'\n",
            " 'em học ngành ktmt hoặc khmt , em có_thể đi du_học không ?'\n",
            " 'ở quê , chưa được học viết chương_trình , em có_thể học được ngành khmt không ?'\n",
            " 'em ở quê , chưa được học viết chương_trình , em có_thể học được ngành khmt không ?'\n",
            " 'em ở quê , chưa được học viết chương_trình , pica có_thể học được ngành khmt không ?'\n",
            " 'em nghe bạn em nói học ngành khmt khó lắm , mà em học không giỏi môn vật_lý , em học có được không ?'\n",
            " 'pica nghe bạn em nói học ngành khmt khó lắm , mà em học không giỏi môn vật_lý , pica học có được không ?'\n",
            " 'em nghe bạn em không học ngành khmt khó lắm , mà em học nói giỏi môn vật_lý , em học có được không ?'\n",
            " 'em nghe bạn em nói học ngành khmt khó lắm , mà em học không giỏi môn vật_lý , em học có được không ?'\n",
            " 'ở trường em dưới quê , em chỉ có học word , excel , window ._vậy , em có học được ngành ktmt không ?'\n",
            " 'ở trường em dưới quê , em không có học word , excel , window ._vậy , em có học được ngành ktmt chỉ ?'\n",
            " 'ở trường em dưới quê , news em chỉ có học word , excel , window ._vậy , em có học được ngành ktmt không ?'\n",
            " 'ở trường em dưới quê , em chỉ có học word , excel , ._vậy , em học được ngành ktmt không ?'\n",
            " 'ở trường em dưới quê , em chỉ có học formulate , excel , windowpane ._vậy , em có học được ngành ktmt không ?'\n",
            " 'có cần phải có kiến_thức / kỹ_năng gì để học được ngành ktmt ?'\n",
            " 'có cần phải có kiến_thức / kỹ_năng gì để học được ktmt ?'\n",
            " 'có cần phải có kiến_thức / kỹ_năng gì để học được ngành ktmt ?'\n",
            " 'có cần phải có kỹ_năng / kiến_thức gì để học được ngành ktmt ?'\n",
            " 'trường có giới_thiệu em miễn nghĩa_vụ quân_sự không ?'\n",
            " 'trường có giới_thiệu em miễn nghĩa_vụ quân_sự không ?'\n",
            " 'trường có giới_thiệu em miễn nghĩa_vụ quân_sự ?'\n",
            " 'trường có giới_thiệu pica miễn nghĩa_vụ quân_sự không ?'\n",
            " 'sau lên em ra trường , em có được học tiếp khi cao nữa hay không ?'\n",
            " 'sau khi em Ra trường , em có được học tiếp lên cao nữa hay không ?'\n",
            " 'sau khi em ra trường , em có được học tiếp lên cao nữa hay không ?'\n",
            " 'sau khi em ra trường , có được học tiếp lên cao nữa hay không ?'\n",
            " 'em có nghe chương_trình tiên_tiến ._vậy chương_trình tiên_tiến là gì ?'\n",
            " 'em có nghe chương_trình tiên_tiến ._vậy chương_trình tiên_tiến là gì ?'\n",
            " 'em nghe chương_trình tiên_tiến ._vậy chương_trình tiên_tiến là gì ?'\n",
            " 'pica có nghe chương_trình tiên_tiến ._vậy chương_trình tiên_tiến là gì ?'\n",
            " 'học ngành khmt , ktmt mất bao_nhiêu năm ?'\n",
            " 'học ngành khmt , năm mất bao_nhiêu ktmt ?'\n",
            " 'khoa kh & kt máy_tính có đào_tạo song ngành hay không ?'\n",
            " 'khoa kh & kt máy_tính có đào_tạo hay ngành song không ?'\n",
            " 'khoa kh & kt máy_tính có đào_tạo song ngành hay ?'\n",
            " 'khoa kh & kt máy_tính có đào_tạo strain ngành hay không ?'\n",
            " 'khoa kh & kt máy_tính có đào_tạo song ngành hay không ?'\n",
            " 'khoa kh & carat máy_tính có chương_trình liên_thông hay không ?'\n",
            " 'khoa kh & kt chương_trình có máy_tính liên_thông hay không ?'\n",
            " 'khoa kh & kt máy_tính có chương_trình liên_thông hay không ?'\n",
            " 'khoa kh & kt máy_tính có chương_trình liên_thông không ?'\n",
            " 'khoa kh & kt máy_tính có chương_trình dành cho người vừa đi làm vừa đi học hay không ? thí_sinh cần tham_gia thi_tuyển hay chỉ cần xét tuyển ?'\n",
            " 'khoa cần & kt máy_tính có chương_trình dành cho người vừa đi làm vừa đi học hay không ? thí_sinh kh tham_gia thi_tuyển hay chỉ cần xét tuyển ?'\n",
            " 'khoa kh & kt máy_tính có chương_trình dành người vừa đi vừa đi học hay không ? thí_sinh cần tham_gia thi_tuyển hay chỉ cần xét tuyển ?'\n",
            " 'khoa kh & carat máy_tính có chương_trình dành cho người vừa đi làm vừa đi học hay không ? thí_sinh cần tham_gia thi_tuyển hay chỉ cần xét tuyển ?'\n",
            " 'ngành kỹ_thuật máy_tính là ngành học về vấn_đề gì ?'\n",
            " 'ngành kỹ_thuật máy_tính là ngành về vấn_đề gì ?'\n",
            " 'ngành kỹ_thuật máy_tính là ngành học về vấn_đề gì ?'\n",
            " 'có các chuyên_ngành / hướng nào trong ngành kỹ_thuật máy_tính ?'\n",
            " 'có các chuyên_ngành / hướng nào máy_tính ngành kỹ_thuật trong ?'\n",
            " 'có các chuyên_ngành / hướng nào trong ngành kỹ_thuật máy_tính ?'\n",
            " 'có_thể học về trí_tuệ nhân_tạo trong ngành ktmt không ?'\n",
            " 'có_thể học về trí_tuệ nhân_tạo trong ngành ktmt không ?'\n",
            " 'có_thể học trí_tuệ nhân_tạo trong ngành ktmt không ?'\n",
            " 'có_thể học về trí_tuệ nhân_tạo ngành trong ktmt không ?'\n",
            " 'có_thể học về an_ninh mạng trong ngành ktmt không ?'\n",
            " 'có_thể học về an_ninh mạng ngành ktmt không ?'\n",
            " 'không học về an_ninh mạng trong ngành ktmt có_thể ?'\n",
            " 'có_thể học về an_ninh mạng trong ngành ktmt không ?'\n",
            " 'có_thể học về iot trong ngành ktmt không ?'\n",
            " 'có_thể iot về học trong ngành ktmt không ?'\n",
            " 'có_thể học về iot ngành ktmt không ?'\n",
            " 'có_thể học về hệ_thống nhúng trong ngành ktmt không ?'\n",
            " 'có_thể ngành về hệ_thống nhúng trong học ktmt không ?'\n",
            " 'có_thể học về hệ_thống nhúng trong ngành ktmt không ?'\n",
            " 'có_thể học về tính_toán hiệu_năng cao – điện_toán đám_mây trong ngành ktmt không ?'\n",
            " 'có_thể về tính_toán hiệu_năng cao – điện_toán đám_mây trong ngành ktmt không ?'\n",
            " 'có_thể học về tính_toán hiệu_năng cao – điện_toán đám_mây trong ngành ktmt không ?'\n",
            " 'điện_toán học về tính_toán hiệu_năng cao – có_thể đám_mây trong ngành ktmt không ?'\n",
            " 'có_thể học về thiết_kế chip / thiết_kế vi_mạch trong ngành ktmt không ?'\n",
            " 'có_thể học về thiết_kế bit / thiết_kế vi_mạch trong ngành ktmt không ?'\n",
            " 'có_thể học thiết_kế chip / thiết_kế vi_mạch trong ngành ktmt không ?'\n",
            " 'có_thể học về ktmt chip / thiết_kế vi_mạch trong ngành thiết_kế không ?'\n",
            " 'em nghe bạn em nói , trường đhbk có cơ_sở ở thủ_đức . nếu em đăng_ký học ngành khmt , em học ở cơ_sở nào ?'\n",
            " 'em nghe bạn nào nói , trường đhbk có cơ_sở ở thủ_đức . nếu em đăng_ký học ngành khmt , em học ở cơ_sở em ?'\n",
            " 'em nghe bạn em nói , trường đhbk có cơ_sở ở thủ_đức . nếu em đăng_ký học ngành khmt , em học ở cơ_sở nào ?'\n",
            " 'pica nghe bạn pica nói , trường đhbk có cơ_sở ở thủ_đức . nếu em đăng_ký học ngành khmt , em học ở cơ_sở nào ?'\n",
            " 'các thành_tích nổi_bật của sv ngành ktmt trong những năm qua là gì ?'\n",
            " 'thành_tích nổi_bật của sv ngành ktmt trong những năm qua là gì ?'\n",
            " 'các thành_tích nổi_bật của sv ngành ktmt trong những năm gì là qua ?'\n",
            " 'các thành_tích nổi_bật của sv ngành ktmt trong những năm qua là gì ?'\n",
            " 'nếu cần thêm thông_tin hoặc cần tư_vấn về ngành kỹ_thuật máy_tính thì liên_hệ ở đâu ?'\n",
            " 'nếu cần thêm thông_tin hoặc kỹ_thuật tư_vấn về ngành cần máy_tính thì liên_hệ ở đâu ?'\n",
            " 'nếu cần thêm thông_tin cần tư_vấn về ngành kỹ_thuật máy_tính thì liên_hệ ở đâu ?'\n",
            " 'nếu cần thêm thông_tin hoặc cần tư_vấn về ngành kỹ_thuật máy_tính thì liên_hệ ở đâu ?'\n",
            " 'trường có làm_việc vào 7 không ạ ?'\n",
            " 'trường có làm_việc vào thứ 7 không ạ ?'\n",
            " 'trường có làm_việc vào thứ VII không ạ ?'\n",
            " 'thứ có làm_việc vào trường 7 không ạ ?'\n",
            " 'dạ cho em hỏi là nếu trong học_kỳ , em đăng_kí 28 chỉ mà chỉ đạt có 25 chỉ , em dự_định sẽ đăng_ký môn khác 3 chỉ trong hk hè để bù vào vậy thì có tính là em được phép đăng_ký môn_học của năm tiếp_theo không ạ'\n",
            " 'dạ cho em hỏi là nếu trong học_kỳ , em đăng_kí chỉ chỉ đạt có 25 chỉ , em dự_định sẽ đăng_ký môn khác chỉ trong hk hè để bù vào vậy thì có tính là em phép đăng_ký môn_học của năm tiếp_theo không ạ'\n",
            " 'dạ cho em hỏi là nếu trong học_kỳ , em đăng_kí 28 chỉ mà chỉ đạt có 25 chỉ , em dự_định sẽ đăng_ký môn khác vào chỉ trong hk hè để bù 3 vậy thì có tính là em được tiếp_theo đăng_ký môn_học của năm phép không ạ'\n",
            " 'dạ cho pica hỏi là nếu trong học_kỳ , em đăng_kí twenty-eight chỉ mà chỉ đạt có twenty-five chỉ , em dự_định sẽ đăng_ký môn khác trio chỉ trong hk hè để bù vào vậy thì có tính là em được phép đăng_ký môn_học của năm tiếp_theo không ạ'\n",
            " 'cho em hỏi thời_gian công_bố kết_quả phương_thức 1.1_xét tuyển thẳng theo quy_định của bộ giáo_dục & đào_tạo và ?'\n",
            " 'cho công_bố hỏi thời_gian em kết_quả phương_thức 1.1_xét tuyển thẳng theo quy_định của bộ giáo_dục & đào_tạo và đhqg-hcm ạ ?'\n",
            " 'thầy cô ơi cho e hỏi là khi nào công_bố điểm chuẩn phương_thức utxt 2 ạ'\n",
            " 'thầy cô ơi cho e hỏi là khi nào công_bố điểm chuẩn phương_thức utxt 2 ạ'\n",
            " 'thầy cô ơi cho einsteinium hỏi là khi nào công_bố điểm chuẩn phương_thức utxt 2 ạ'\n",
            " 'thầy cô ơi 2 e hỏi là khi nào công_bố điểm chuẩn phương_thức utxt cho ạ'\n",
            " 'thầy cô cho e hỏi là khi nào công_bố điểm chuẩn phương_thức utxt 2 ạ'\n",
            " 'cho em hỏi phương_thức kết_hợp khi nào mới có điểm_chuẩn ạ'\n",
            " 'cho em hỏi phương_thức kết_hợp khi nào mới có điểm_chuẩn ạ'\n",
            " 'hỏi em cho phương_thức kết_hợp khi nào mới có điểm_chuẩn ạ'\n",
            " 'cho em hỏi phương_thức kết_hợp nào mới có điểm_chuẩn ạ'\n",
            " 'cho em hỏi phương_thức kết_hợp chi nào mới có điểm_chuẩn ạ'\n",
            " 'em thi tổ_hợp các môn xét xã_hội thì có khoa_học tuyển được vào ngành công_nghệ_thông_tin không ạ ?'\n",
            " 'pica thi tổ_hợp các môn khoa_học xã_hội thì có xét tuyển được vào ngành công_nghệ_thông_tin không ạ ?'\n",
            " 'em thi tổ_hợp các môn khoa_học xã_hội thì có xét tuyển được vào ngành công_nghệ_thông_tin không ạ ?'\n",
            " 'em thi tổ_hợp các môn khoa_học xã_hội thì có xét tuyển được vào ngành không ạ ?'\n",
            " 'dạ cho xét hỏi ngành logistic bên trường có em theo khối c k ạ'\n",
            " 'dạ cho em hỏi ngành logistic bên trường có xét theo khối c k '\n",
            " 'dạ cho em hỏi ngành logistic bên trường có xét theo khối c chiliad ạ'\n",
            " 'dạ cho em hỏi ngành logistic bên trường có xét theo khối c k ạ'\n",
            " 'dạ em là thí_sinh chuẩn_bị thi đại_học năm nay , em có nguyện_vọng vào bách_khoa nhưng lúc tạo tài_khoản trên mybk em bị quên mật_khẩu thì giờ em phải làm_sao đây ạ'\n",
            " 'dạ em là thí_sinh chuẩn_bị thi đại_học em nay , em có em vào bách_khoa nhưng lúc tạo tài_khoản trên mybk năm bị quên mật_khẩu thì giờ nguyện_vọng phải làm_sao đây ạ'\n",
            " 'dạ em là thí_sinh chuẩn_bị thi đại_học năm nay , em có nguyện_vọng vào bách_khoa nhưng lúc tạo tài_khoản trên em bị mật_khẩu thì em phải làm_sao đây ạ'\n",
            " 'dạ em là thí_sinh chuẩn_bị thi đại_học năm nay , pica có nguyện_vọng vào bách_khoa nhưng lúc tạo tài_khoản trên mybk pica bị quên mật_khẩu thì giờ pica phải làm_sao đây ạ']\n",
            "237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cal TF-IDF\n",
        "def tf_idf(corpus):\n",
        "    vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3))\n",
        "    vec = vectorizer.fit_transform(corpus)\n",
        "    f_name = vectorizer.get_feature_names_out()\n",
        "    dense = vec.todense()\n",
        "    denselist = dense.tolist()\n",
        "    return denselist, f_name\n",
        "\n",
        "# X_train = np.append(Q,A)\n",
        "# X_train = Q\n",
        "# Y_train = np.append(Q_I,A_I)\n",
        "# Y_train = I\n",
        "\n",
        "dl_train, f_train = tf_idf(X_train)\n",
        "df_train = pd.DataFrame(dl_train, columns=f_train)\n",
        "# print(f'dl_train: {dl_train}\\nf_train: {f_train}\\n len: {len(f_train)}')\n",
        "\n",
        "\n",
        "# dl_test, f_test = tf_idf(X_test)\n",
        "# df_test = pd.DataFrame(dl_test, columns=f_test)\n",
        "\n",
        "# print(f'dl_test: {dl_test}\\nf_test: {f_test}\\n len: {len(f_test)}')\n",
        "\n",
        "# print(f'f_train - f_test: {np.setdiff1d(f_train, f_test)}\\n len: {len(np.setdiff1d(f_train, f_test))}')\n",
        "\n",
        "max_len = len(f_train)\n",
        "print(max_len)\n",
        "# print(type(f_train))\n",
        "\n",
        "# nltk.download('stopwords')\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "\n",
        "print(X_train.shape[0])\n",
        "\n",
        "def sen_to_vec(X, vocab, max_len):\n",
        "      \"\"\"\n",
        "      Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
        "      The output shape should be such that it can be given to `Embedding()` (described in Figure 4).\n",
        "\n",
        "      Arguments:\n",
        "      X -- array of sentences (strings), of shape (m, 1)\n",
        "      vocab -- the list of word (vocab)\n",
        "      max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this.\n",
        "\n",
        "      Returns:\n",
        "      X_vec -- occurrence of word in sentence, of shape (m, max_len)\n",
        "      \"\"\"\n",
        "\n",
        "      m = X.shape[0]        # number of training examples\n",
        "\n",
        "      ### START CODE HERE ###\n",
        "      # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
        "      X_vec = np.zeros([m, max_len])\n",
        "\n",
        "      for i in range(m):                               # loop over training examples\n",
        "\n",
        "          # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
        "          word_tokens = [w.lower() for w in str(X[i]).split(' ')]\n",
        "          no_sw = [w for w in word_tokens if not w in stop_words]\n",
        "          # stem = [ps.stem(w) for w in no_sw]\n",
        "          # filtered_sentence = (\" \").join(stem)\n",
        "          # print(stem)\n",
        "\n",
        "          for j in range(len(no_sw)):\n",
        "            # print(stem[i])\n",
        "            # for j in range(len(stem[i])):\n",
        "            #   print(stem[i][j])\n",
        "              if no_sw[j] in vocab:\n",
        "                for k in range(len(vocab)):\n",
        "                  if no_sw[j] == vocab[k]:\n",
        "                    # print(stem[i])\n",
        "                    X_vec[i][k] += 1.0\n",
        "\n",
        "\n",
        "      ### END CODE HERE ###\n",
        "      return X_vec\n",
        "\n",
        "x_train = sen_to_vec(X_train, f_train, max_len)\n",
        "x_test = sen_to_vec(X_test, f_train, max_len)\n",
        "\n",
        "print(x_train[0])\n",
        "\n",
        "# print(f)\n",
        "# key_word = []\n",
        "# x_train_mat = []\n",
        "# x_test_mat = []\n"
      ],
      "metadata": {
        "id": "epXscq2qR3To",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ddcdd0-9ac3-4f38-bc7c-55e2fec965c9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2315\n",
            "237\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aK7Q8vpUR8vG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# X_train, Y_train = read_csv('E:code/python/chatbot/train.csv')\n",
        "# print(f'type(Y_train): {type(Y_train)}')\n",
        "# test, Y_test = read_csv('E:code/python/chatbot/test.csv')\n",
        "# X_train = tf_idf(lines)\n",
        "classifier = svm.SVC(kernel='linear', gamma='auto', C=3)\n",
        "\n",
        "classifier.fit(x_train, Y_train)\n",
        "\n",
        "# X_test = tf_idf(test)\n",
        "\n",
        "acc = classifier.score(x_test, Y_test)\n",
        "print()\n",
        "print(\"Test accuracy = \", acc)\n",
        "\n",
        "# Y_pred = classifier.predict(dl_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FdIkO4XSDz_",
        "outputId": "46091281-ce64-4c98-e2c3-7f907b1c555c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy =  0.9622641509433962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C = 3\n",
        "# y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
        "wrong = []\n",
        "X_test_indices = sen_to_vec(x_test, f_train, max_len)\n",
        "pred = classifier.predict(X_test_indices)\n",
        "for i in range(len(x_test)):\n",
        "    x = X_test_indices\n",
        "    num = np.argmax(pred[i])\n",
        "    if(num != Y_test[i]):\n",
        "        wrong.append(num)\n",
        "        print(str(i+1) + '.' )\n",
        "        print('Input: ' + str(X_test[i]))\n",
        "        print('Expected: '+ str(Y_test[i]))\n",
        "        print('Prediction: '+ str(num))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKAYpJLCrJcd",
        "outputId": "7f9fd9f3-4ce0-45ba-c897-9164603c6d32"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.\n",
            "Input: khoa kh & kt máy_tính có chương_trình dành cho người vừa đi làm vừa thi_tuyển học hay không ? thí_sinh cần tham_gia đi hay chỉ cần xét tuyển ?\n",
            "Expected: 1\n",
            "Prediction: 0\n",
            "2.\n",
            "Input: cho em hỏi công_thức phương_thức điểm tính 5 xét tuyển kết_hợp nhiều tiêu_chí ạ ?\n",
            "Expected: 1\n",
            "Prediction: 0\n",
            "3.\n",
            "Input: cho pica hỏi là pt5 xét tuyển thì không có đgnl có đủ điều_kiện xét không ạ\n",
            "Expected: 1\n",
            "Prediction: 0\n",
            "4.\n",
            "Input: cho em hỏi công_thức phương_thức điểm tính 5 xét tuyển kết_hợp nhiều tiêu_chí ạ ?\n",
            "Expected: 1\n",
            "Prediction: 0\n",
            "5.\n",
            "Input: điểm xét tuyển theo phương_thức 2 ưu_tiên xét tuyển có được cộng thêm điểm thưởng khi có các thành_tích khác không ạ ?\n",
            "Expected: 1\n",
            "Prediction: 0\n",
            "6.\n",
            "Input: cho em hỏi trường xét phương_thức kết_hợp Phoebe là vào ngày mấy ạ\n",
            "Expected: 2\n",
            "Prediction: 0\n",
            "7.\n",
            "Input: cho em hỏi còn đợt được hồ_sơ cho chương_trình đào_tạo thạc_sĩ phương_thức tuyển thẳng nào không . do em chưa mong đủ hồ_sơ nên đợt nộp ngày 16/6/2023 em không_thể nộp kịp . em chuẩn_bị nộp phản_hồi . xin cám_ơn admin\n",
            "Expected: 2\n",
            "Prediction: 0\n",
            "8.\n",
            "Input: làm_sao hồ_sơ biết để gửi đi đã hợp_lệ hay chưa ạ ?\n",
            "Expected: 3\n",
            "Prediction: 0\n",
            "9.\n",
            "Input: hồ_sơ xét tuyển theo phương_thức two của pica bị sai thông_tin khu_vực ưu_tiên thì có cần nộp lại bộ hồ_sơ khác không ạ ?\n",
            "Expected: 3\n",
            "Prediction: 0\n",
            "10.\n",
            "Input: làm_sao hồ_sơ biết để gửi đi đã hợp_lệ hay chưa ạ ?\n",
            "Expected: 3\n",
            "Prediction: 0\n",
            "11.\n",
            "Input: sự khác_biệt ngành kỹ_thuật máy_tính và ngành khoa_học máy_tính ở trường đại_học bách_khoa –_đhqg tphcm là gì ?\n",
            "Expected: 4\n",
            "Prediction: 0\n",
            "12.\n",
            "Input: ngành và ktmt , ngành học nào_dễ hơn .\n",
            "Expected: 4\n",
            "Prediction: 0\n",
            "13.\n",
            "Input: sự khác_biệt giữa kỹ_thuật máy_tính và là gì ?\n",
            "Expected: 4\n",
            "Prediction: 0\n",
            "14.\n",
            "Input: ngành khmt ngành ktmt , và học nào_dễ hơn .\n",
            "Expected: 4\n",
            "Prediction: 0\n",
            "15.\n",
            "Input: sang ban_đầu em học ngành khmt , sau đó , em thấy không phù_hợp , em có_thể chuyển nếu ngành ktmt được không ?\n",
            "Expected: 5\n",
            "Prediction: 0\n",
            "16.\n",
            "Input: sang ban_đầu em học ngành khmt , sau đó , em thấy không phù_hợp , em có_thể chuyển nếu ngành ktmt được không ?\n",
            "Expected: 5\n",
            "Prediction: 0\n",
            "17.\n",
            "Input: em muốn học làm robot , điều_khiển từ xa các thiết_bị trong gia_đình thì em nên học ngành nào ?\n",
            "Expected: 6\n",
            "Prediction: 0\n",
            "18.\n",
            "Input: em muốn học làm robot , điều_khiển từ xa các thiết_bị trong gia_đình thì em nên học ngành nào ?\n",
            "Expected: 6\n",
            "Prediction: 0\n",
            "19.\n",
            "Input: em muốn làm học robot , điều_khiển từ xa các thiết_bị trong gia_đình thì em nên học ngành nào ?\n",
            "Expected: 6\n",
            "Prediction: 0\n",
            "20.\n",
            "Input: học_phí có đắt không ?\n",
            "Expected: 7\n",
            "Prediction: 0\n",
            "21.\n",
            "Input: học_phí của ngành , ktmt ?\n",
            "Expected: 7\n",
            "Prediction: 0\n",
            "22.\n",
            "Input: cho em hỏi học_phí ngành khoa_học máy_tính chương_trình giảng_dạy bằng tiếng anh của trường được không ạ ?\n",
            "Expected: 7\n",
            "Prediction: 0\n",
            "23.\n",
            "Input: em học ngành khmt Re trường có việc_làm không ?\n",
            "Expected: 8\n",
            "Prediction: 0\n",
            "24.\n",
            "Input: trường có giới_thiệu việc_làm cho pica không ?\n",
            "Expected: 8\n",
            "Prediction: 0\n",
            "25.\n",
            "Input: trường có giới_thiệu việc_làm cho em ?\n",
            "Expected: 8\n",
            "Prediction: 0\n",
            "26.\n",
            "Input: ktx gần ở quận 10 có bách_khoa trường không ạ ?\n",
            "Expected: 9\n",
            "Prediction: 0\n",
            "27.\n",
            "Input: trường có ký_túc_xá không ? em được ở ktx không ?\n",
            "Expected: 9\n",
            "Prediction: 0\n",
            "28.\n",
            "Input: em học ngành ktmt không khmt , em có_thể đi du_học được hoặc ?\n",
            "Expected: 10\n",
            "Prediction: 0\n",
            "29.\n",
            "Input: em ở khmt , chưa được học viết chương_trình , em có_thể học được ngành quê không ?\n",
            "Expected: 11\n",
            "Prediction: 0\n",
            "30.\n",
            "Input: em ở quê , chưa được học viết chương_trình , em có_thể học được ngành khmt không ?\n",
            "Expected: 11\n",
            "Prediction: 0\n",
            "31.\n",
            "Input: em nghe bạn em nói học ngành khmt khó lắm , mà em học không giỏi vật_lý , em học được không ?\n",
            "Expected: 11\n",
            "Prediction: 0\n",
            "32.\n",
            "Input: miễn có giới_thiệu em trường nghĩa_vụ quân_sự không ?\n",
            "Expected: 12\n",
            "Prediction: 0\n",
            "33.\n",
            "Input: sau khi em ra trường , em có được học tiếp lên cao nữa hay không ?\n",
            "Expected: 13\n",
            "Prediction: 0\n",
            "34.\n",
            "Input: có_thể học về iot trong ngành ktmt không ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "35.\n",
            "Input: có các / hướng nào trong ngành kỹ_thuật máy_tính ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "36.\n",
            "Input: khoa kh & kt máy_tính có chương_trình liên_thông hay không ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "37.\n",
            "Input: khoa kh & kt máy_tính có chương_trình dành cho người vừa đi làm vừa đi học hay không ? thí_sinh cần tham_gia thi_tuyển hay chỉ cần xét tuyển ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "38.\n",
            "Input: có_thể học về hệ_thống nhúng trong ngành ktmt ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "39.\n",
            "Input: học ngành khmt , ktmt mất bao_nhiêu năm ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "40.\n",
            "Input: có_thể học về iot trong ngành ktmt không ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "41.\n",
            "Input: có_thể học về thiết_kế chip / thiết_kế vi_mạch trong ngành ktmt không ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "42.\n",
            "Input: ngành kỹ_thuật máy_tính là ngành về học vấn_đề gì ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "43.\n",
            "Input: học ngành , ktmt mất bao_nhiêu năm ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "44.\n",
            "Input: em có nghe chương_trình gì ._vậy chương_trình tiên_tiến là tiên_tiến ?\n",
            "Expected: 14\n",
            "Prediction: 0\n",
            "45.\n",
            "Input: em nghe bạn em nói , trường đhbk cơ_sở ở thủ_đức . nếu em đăng_ký học ngành , em học ở cơ_sở nào ?\n",
            "Expected: 15\n",
            "Prediction: 0\n",
            "46.\n",
            "Input: trường có làm_việc vào thứ 7 không ạ ?\n",
            "Expected: 17\n",
            "Prediction: 0\n",
            "47.\n",
            "Input: dạ cho em hỏi là nếu trong học_kỳ , em đăng_kí 28 chỉ mà chỉ đạt có 25 chỉ , em dự_định sẽ đăng_ký môn khác 3 chỉ trong hk hè để bù vào vậy thì có tính là em được phép đăng_ký môn_học của năm tiếp_theo không ạ\n",
            "Expected: 18\n",
            "Prediction: 0\n",
            "48.\n",
            "Input: cho em hỏi thời_gian công_bố kết_quả phương_thức 1.1_xét tuyển thẳng theo quy_định của bộ giáo_dục & đào_tạo và đhqg-hcm ạ ?\n",
            "Expected: 19\n",
            "Prediction: 0\n",
            "49.\n",
            "Input: cho em hỏi thời_gian công_bố kết_quả phương_thức 1.1_xét tuyển thẳng theo quy_định của bộ giáo_dục & đào_tạo và đhqg-hcm ạ ?\n",
            "Expected: 19\n",
            "Prediction: 0\n",
            "50.\n",
            "Input: cho pica hỏi thời_gian công_bố kết_quả phương_thức unity.1_xét tuyển thẳng theo quy_định của bộ giáo_dục & đào_tạo và đhqg-hcm ạ ?\n",
            "Expected: 19\n",
            "Prediction: 0\n",
            "51.\n",
            "Input: em thi tổ_hợp các môn khoa_học xã_hội thì có xét tuyển được vào ngành công_nghệ_thông_tin không ạ ?\n",
            "Expected: 20\n",
            "Prediction: 0\n",
            "52.\n",
            "Input: dạ cho em hỏi ngành logistic bên trường có xét theo khối c k ạ\n",
            "Expected: 20\n",
            "Prediction: 0\n",
            "53.\n",
            "Input: dạ em là thí_sinh chuẩn_bị thi đại_học năm nay , em có nguyện_vọng vào bách_khoa nhưng lúc tạo tài_khoản trên mybk em bị quên mật_khẩu thì giờ em phải làm_sao đây ạ\n",
            "Expected: 21\n",
            "Prediction: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def code_to_str(code):\n",
        "  # label_dict = {\"0\": \"card delay\",\n",
        "  #                   \"1\": \"card info issue\",\n",
        "  #                   \"2\": \"balance issue\"\n",
        "  #            }\n",
        "  label_dict = {\"1\": \"Hỏi về phương thức tuyển sinh\",\n",
        "                \"2\": \"Hỏi về thời gian đăng ký\",\n",
        "                \"3\": \"Hỏi về hồ sơ tuyển sinh\",\n",
        "                \"4\": \"so sánh các ngành\",\n",
        "                \"5\": \"chuyển ngành / chương trình học trong tương lai\",\n",
        "                \"6\": \"chọn ngành học\",\n",
        "                \"7\": \"học phí\",\n",
        "                \"8\": \"triển vọng nghề nghiệp\",\n",
        "                \"9\": \"KTX trường\",\n",
        "                \"10\": \"cơ hội du học\",\n",
        "                \"11\": \"kiến thức đầu vào của ngành\",\n",
        "                \"12\": \"hoãn nghĩa vụ quân sự\",\n",
        "                \"13\": \"đào tạo sau đại học\",\n",
        "                \"14\": \"chương trình đào tạo\",\n",
        "                \"15\": \"địa điểm học tập\",\n",
        "                \"16\": \"uy tín đào tạo\",\n",
        "                \"17\": \"thông tin thêm\",\n",
        "                \"18\": \"đăng kí môn học\",\n",
        "                \"19\": \"thời gian trả / công bố kết quả\",\n",
        "                \"20\": \"khối tuyển sinh\",\n",
        "                \"21\": \"vấn đề phần mềm\"}\n",
        "  return label_dict[str(code)]"
      ],
      "metadata": {
        "id": "jJJJdrwygQrd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user = np.array([input('> ')])\n",
        "user_i = sen_to_vec(user, f_train, max_len)\n",
        "pred_u = int(classifier.predict(user_i))\n",
        "print(f'out: {code_to_str(pred_u)}')"
      ],
      "metadata": {
        "id": "98Mj0o_AyHHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070c92b6-2f06-4f85-e418-039addac06e6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Học phí của cơ điện tử\n",
            "out: đào tạo sau đại học\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chương trình tiên tiến là gì?\n",
        "em muốn hỏi về phương thức 2 ưu tiên xét tuyển\n",
        "em muốn hỏi về phương thức 2\n",
        "khoa có những ngành học nào\n",
        "học phí của trường\n",
        "phương thức xét tuyển 5\n",
        "các phương thức xét tuyển của trường\n",
        "Học phí của cơ điện tử"
      ],
      "metadata": {
        "id": "FMdida7K2M25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textattack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOE3NETvGosB",
        "outputId": "e87d1a63-c37e-4895-a0d3-ae1ea0c180ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textattack\n",
            "  Downloading textattack-0.3.8-py3-none-any.whl (418 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.7/418.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bert-score>=0.3.5 (from textattack)\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from textattack) (0.6.2)\n",
            "Collecting flair (from textattack)\n",
            "  Downloading flair-0.12.2-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from textattack) (3.12.2)\n",
            "Collecting language-tool-python (from textattack)\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Collecting lemminflect (from textattack)\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lru-dict (from textattack)\n",
            "  Downloading lru_dict-1.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Collecting datasets==2.4.0 (from textattack)\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textattack) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.10.1)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.12.1)\n",
            "Requirement already satisfied: transformers>=4.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (4.30.2)\n",
            "Collecting terminaltables (from textattack)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from textattack) (4.65.0)\n",
            "Collecting word2number (from textattack)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words (from textattack)\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from textattack) (9.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.7.1)\n",
            "Collecting pinyin==0.4.0 (from textattack)\n",
            "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from textattack) (0.42.1)\n",
            "Collecting OpenHowNet (from textattack)\n",
            "  Downloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
            "Collecting pycld2 (from textattack)\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click<8.1.0 (from textattack)\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (9.0.0)\n",
            "Collecting dill<0.3.6 (from datasets==2.4.0->textattack)\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (2.27.1)\n",
            "Collecting xxhash (from datasets==2.4.0->textattack)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.4.0->textattack)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->textattack) (23.1)\n",
            "Collecting responses<0.19 (from datasets==2.4.0->textattack)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2022.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.6.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (0.3.1)\n",
            "Requirement already satisfied: gensim>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.3.1)\n",
            "Collecting segtok>=1.5.7 (from flair->textattack)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting mpld3==0.3 (from flair->textattack)\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.2)\n",
            "Collecting sqlitedict>=1.6.0 (from flair->textattack)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated>=1.2.4 (from flair->textattack)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.2.7)\n",
            "Collecting boto3 (from flair->textattack)\n",
            "  Downloading boto3-1.27.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.2 (from flair->textattack)\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.8.10)\n",
            "Collecting langdetect (from flair->textattack)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.9.2)\n",
            "Collecting ftfy (from flair->textattack)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting janome (from flair->textattack)\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gdown==4.4.0 (from flair->textattack)\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting conllu>=4.0 (from flair->textattack)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting wikipedia-api (from flair->textattack)\n",
            "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
            "Collecting pptree (from flair->textattack)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad (from flair->textattack)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.1 (from flair->textattack)\n",
            "  Downloading transformer_smaller_training_vocab-0.2.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair->textattack) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair->textattack) (4.11.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (1.2.0)\n",
            "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anytree (from OpenHowNet->textattack)\n",
            "  Downloading anytree-2.9.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (67.7.2)\n",
            "Collecting sentencepiece (from bpemb>=0.3.2->flair->textattack)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.4->flair->textattack) (1.14.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->textattack) (1.3.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair->textattack) (6.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair->textattack) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair->textattack) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair->textattack) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair->textattack) (0.10.9.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->textattack) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair->textattack) (3.1.0)\n",
            "Requirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.21.0->textattack) (3.20.3)\n",
            "Collecting botocore<1.31.0,>=1.30.0 (from boto3->flair->textattack)\n",
            "  Downloading botocore-1.30.0-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->flair->textattack)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->flair->textattack)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->flair->textattack) (0.2.6)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.4.0->textattack)\n",
            "  Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.20.2 (from transformers>=4.21.0->textattack)\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.4.0->flair->textattack) (2.4.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers>=4.21.0->textattack) (5.9.5)\n",
            "Building wheels for collected packages: pinyin, gdown, mpld3, pycld2, word2number, docopt, sqlitedict, langdetect, pptree\n",
            "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630476 sha256=592a51395b19c36158a1e70497990c7931bcdb0fefb1f71642ba515eb5abf4a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/38/af/616fc6f154aa5bae65a1da12b22d79943434269f0468ff9b3f\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=ed115c75c36dbb81d2dcc99878dc0fdb1309e6c4b49f14b90171b030f745954f\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/0b/3f/6ddf67a417a5b400b213b0bb772a50276c199a386b12c06bfc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116685 sha256=25fce72927b2e1d622ba0383e7903666b6b0a85387fc1b01f2d2c6deac437de5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/92/f7/45d9aac5dcfb1c2a1761a272365599cc7ba1050ce211a3fd9a\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=9915977 sha256=0c31144f5b6fac19658862840d99e933643ebc33915994da6b833b011a84b69f\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5569 sha256=c0b09760d502ced393bec197643df17065ac40ec806f254241d87f1dc879f354\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=4fe9a0789e7ca2da19f8efc29d5e5d1f584190aa71025fe32f0c906ac7fc1eb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=ecc04c3d6b1f314de6aeae25175a01ec476c41335eddc326a662144593dbe5bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=9eadecf5aa3d37bf7bcf45dbaccaf61271837b205fb70faf8276fee0a517cb20\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4609 sha256=4567580d9b064791a228346957139712afc280fef0e3259469f55e8c9da5a2e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "Successfully built pinyin gdown mpld3 pycld2 word2number docopt sqlitedict langdetect pptree\n",
            "Installing collected packages: word2number, sqlitedict, sentencepiece, pycld2, pptree, pinyin, mpld3, lru-dict, janome, docopt, xxhash, terminaltables, segtok, num2words, lemminflect, langdetect, jmespath, ftfy, dill, deprecated, conllu, click, anytree, wikipedia-api, responses, pytorch-revgrad, OpenHowNet, multiprocess, language-tool-python, botocore, accelerate, s3transfer, gdown, bpemb, datasets, boto3, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.3\n",
            "    Uninstalling click-8.1.3:\n",
            "      Successfully uninstalled click-8.1.3\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed OpenHowNet-2.0 accelerate-0.20.3 anytree-2.9.0 bert-score-0.3.13 boto3-1.27.0 botocore-1.30.0 bpemb-0.3.4 click-8.0.4 conllu-4.5.3 datasets-2.4.0 deprecated-1.2.14 dill-0.3.5.1 docopt-0.6.2 flair-0.12.2 ftfy-6.1.1 gdown-4.4.0 janome-0.5.0 jmespath-1.0.1 langdetect-1.0.9 language-tool-python-2.7.1 lemminflect-0.2.3 lru-dict-1.2.0 mpld3-0.3 multiprocess-0.70.13 num2words-0.5.12 pinyin-0.4.0 pptree-3.1 pycld2-0.41 pytorch-revgrad-0.2.0 responses-0.18.0 s3transfer-0.6.1 segtok-1.5.11 sentencepiece-0.1.99 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.8 transformer-smaller-training-vocab-0.2.4 wikipedia-api-0.6.0 word2number-1.1 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textattack.augmentation import EasyDataAugmenter\n",
        "\n",
        "text = \"muốn giải bài toán tháp Hà Nội rất khó\"\n",
        "\n",
        "eda_aug = EasyDataAugmenter()\n",
        "\n",
        "aug = np.array(eda_aug.augment(text))\n",
        "print(len(aug))\n",
        "print(aug)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2K5iB2SGrHF",
        "outputId": "c5adcfcc-3593-459d-9213-f5f305e7ed37"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "['muốn tháp bài toán giải Hà Nội rất khó'\n",
            " 'muốn giải bài toán tháp Hà Nội rất khó'\n",
            " 'muốn giải bài tháp Hà Nội rất khó']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ou0g_AvDZbNC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}